\documentclass[letterpaper, twoside, 12pt]{book}
\usepackage{notes}




\title{MATH 3142 Notes | Spring 2016}
\date{Updated: \today}
\author{Daniel Gruszczynski\\ UNC Charlotte}

\begin{document}

\maketitle

This document is a template for you to take notes in my MATH 3142 course.
For your note check grade, you are required to complete all proofs/solutions
for the problems specified. This template will be updated periodically
throughout the course; you are responsible for updating your copy
as the template is updated. See the syllabus for more details.

You should maintain your notes on Overleaf.com and provide me with a
link so I can check on them. I'll give you notice before notes are ``due'';
when they are due I will download a copy myself from Overleaf.

This is not a replacement for the textbook for this course,
\textit{Advanced Calculus} by Patrick M. Fitzpatrick. Many proofs are
outlined in that text, as well as all the relevant definitions and other
results not included in these notes.

A proof is valid if and only if it uses concepts proven previously in
the book. For example, you cannot prove a lemma in Chapter 6 using
a theorem from Chapter 10, but using a proposition from Chapter 4
is allowed.

I hope you enjoy working through these results. Please email me with
any questions.

\noindent| Dr. Steven Clontz \(\<\)sclontz5@uncc.edu\(\>\)
















\setcounter{chapter}{5}
\chapter{Integration: Two Fundamental Theorems}







\section{Darboux Sums: Upper and Lower Integrals}

\begin{definition}
    Let \(n\) be a natural number. We define \([n] = \{1, 2, ..., n\}\). If 
    \(i\) is an index, we write ``for \(i \in [n]\)'' in place of the usual 
    ``for \(1 \leq i \leq n\).''
\end{definition}

\begin{lemma}[6.1]
  Suppose that the function \(f:[a,b]\to\mb R\) is bounded and the numbers
  \(m,M\) have the property that
  \[
    m\leq f(x)\leq M
  \]
  for all \(x\) in \([a,b]\). Then, if \(P\) is a partition of the domain
  \([a,b]\),
  \[
    m(b-a)\leq L(f,P)
      \text{ and }
    U(f,P)\leq M(b-a)
  .\]
\end{lemma}

\begin{proof}
    Let \(P = \{x_{0}, x_{1}, ..., x_{n}\}\) be a partition on \([a,b]\).
    By assumption, \(m\) is a lower bound of \(f([a,b])\). Restricting
    \(f\) to \([x_{i-1}, x_{i}]\), we have \(m \leq m_{i}\) for all \(i \in [n]\)
    since \(m_{i}\) is the infimum of \(f([x_{i-1}, x_{i}])\). Then, by definition,
    \begin{align*}
        L(f, P) &= \sum_{i = 1}^{n} m_{i}(x_{i} - x_{i-1}) \\ 
                &\geq \sum_{i = 1}^{n} m (x_{i} - x_{i-1}) \\
                &= m \sum_{i = 1}^{n} (x_{i} - x_{i-1}) \\
                &= m (b - a) .\\
    \end{align*}
    Similarly, \(M\) is an upper bound of \(f([a,b])\) and so, when restricting \(f\) 
    to \([x_{i-1}, x_{i}]\), we have \(M \geq M_{i}\) since \(M_{i}\) is the supremum of 
    \(f([x_{i-1}, x_{i}])\) (for all \(i \in [n]\)). Hence, we have
    \begin{align*}
        U(f, P) &= \sum_{i = 1}^{n} M_{i}(x_{i} - x_{i - 1}) \\
                &\leq \sum_{i = 1}^{n} M(x_{i} - x_{i - 1}) \\
                &= M \sum_{i = 1}^{n} (x_{i} - x_{i - 1}) \\
                &= M(b - a) .\\
    \end{align*}

    Therefore, \(m(b - a) \leq L(f, P)\) and \(U(f, P) \leq M(b - a) \). 
\end{proof}


\begin{lemma}[6.2, The Refinement Lemma]
  Suppose that the function \(f:[a,b]\to\mb R\) is bounded and that \(P\)
  is a partition of its domain \([a,b]\). If \(P^\star\) is a refinement
  of \(P\), then
  \[
    L(f,P)\leq L(f,P^\star)
      \text{ and }
    U(f,P^\star)\leq U(f,P)
  .\]
\end{lemma}

\begin{proof}
    Let \(P = \{x_{0}, x_{1}, ..., x_{n}\}\) be a partition on \([a,b]\),
    and let \(P^*\) be its refinement. For \(i \in [n]\), define \(P_{i}\) 
    to be the partition on \([x_{i-1}, x_{i}]\) by the points of 
    \(P^*\) inside this interval. Since \(m_{i} \leq f(x)\) for \(x \in [x_{i-1},x_{i}]\),
    applying the previous lemma to the restriction of \(f\) on \([x_{i-1}, x_{i}]\),
    we have \( m_{i}(x_{i} - x_{i-1}) \leq L(f, P_{i})\). It follows that
    \begin{align*} 
        L(f, P) &= \sum_{i=1}^{n} m_{i}(x_{i} - x_{i - 1}) \\
                &\leq \sum_{i = 1}^{n} L(f, P_{i}) \\
                &= L(f, P^*). \\
    \end{align*}

    Likewise, the previous lemma gives us \(M_{i}(x_{i} - x_{i-1}) \geq U(f, P_{i})\).
    Hence,
    \begin{align*}
        U(f, P) &= \sum_{i=1}^{n} M_{i}(x_{i} - x_{i-1}) \\
                &\geq \sum_{i=1}^{n} U(f, P_{i}) \\
                &= U(f, P^*). \\
    \end{align*}
\end{proof}


\begin{lemma}[6.3]
  Suppose that the function \(f:[a,b]\to\mb R\) is bounded and that
  \(P_1,P_2\) are partitions of its domain. Then \(L(f,P_1)\leq U(f,P_2)\).
\end{lemma}

\begin{proof}
    Let \(P = P_1 \cup P_2\) be the common refinement of partitions \(P_1\)
    and \(P_2\). By the Refinement Lemma, \(L(f, P_{1}) \leq L(f, P)\)
    and \(U(f, P) \leq U(f, P_{2})\). Then, since \(L(f, P) \leq U(f, P)\),
    the transitivity of \(\leq\) implies that \(L(f, P_{1}) \leq U(f, P_{2})\).
\end{proof}


\begin{lemma}[6.4]
  For a bounded function \(f:[a,b]\to\mb R\),
  \[
    \underline{\int_a^b} f
      \leq
    \overline{\int_a^b} f
  .\]
\end{lemma}

\begin{proof}
    Let \(P\) be any partition on \([a,b]\). By the previous lemma,
    \(U(f, P) \geq L(f, P')\) for all partitions \(P'\) on \([a,b]\). 
    It follows that
    \[ \underline{\int_a^b} f \leq U(f, P) . \]
    Since \(P\) was arbitrary, the above shows that \(\underline{\int_a^b} f\)
    is a lower bound for all such \(U(f, P)\). Therefore,
    \[ \underline{\int_a^b} f \leq \overline{\int_a^b} f .\]
\end{proof}

\begin{exercise}[2]
  For an interval \([a,b]\) and a positive number \(\delta\),
  show that there is a partition \(P=\{x_i:0\leq i\leq n\}\) of
  \([a,b]\) such that each partition interval \([x_i,x_{i+1}]\)
  of \(P\) has length less than \(\delta\).
\end{exercise}

\begin{solution}
    Let \([a,b]\) be an interval (\(b > a\)) and \(\delta > 0\).
    By the Archimedean property, there exists a natural number
    \(n\) such that \(\frac{\delta}{b - a} > \frac{1}{n}\). It follows that
    we can form partition intervals of equal length \(\frac{b - a}{n}\):
    \begin{align*}
        \delta &> \frac{b - a}{n} \\
               &= \frac{1}{n} \sum_{i=0}^{n - 1} (x_{i + 1} - x_{i}) \\
               &= \frac{1}{n}[ n (x_{i + 1} - x_{i}) ] \\
               &= x_{i + 1} - x_{i} \\
    \end{align*}
\end{solution}


\begin{exercise}[3]
  Suppose that the bounded function \(f:[a,b]\to\mb R\) has the property
  that for each rational number \(x\) in the interval \([a,b]\),
  \(f(x)=0\). Prove that
  \[
    \underline{\int_a^b}f
      \leq
    0
      \leq
    \overline{\int_a^b}f
  .\]
\end{exercise}

\begin{solution}
    Let \(P = \{x_{0}, x_{1}, ... , x_{n}\}\) be an arbitrary partition on \([a,b]\).
    Since \(\mb Q\) is dense in \(\mb R\), \(m_{i} \leq 0\) and \(M_{i} \geq 0\) for
    all \(i \in [n]\). This implies \(L(f, P) \leq 0\) and \(U(f, P) \geq 0\). 
    Consequently, 
    \[ \underline{\int_a^b} f \leq 0 \leq \overline{\int_a^b} f .\]
\end{solution}


\begin{exercise}[6]
  Suppose that \(f:[a,b]\to\mb R\) is a bounded function for which there is
  a partition \(P\) of \([a,b]\) with \(L(f,P)=U(f,P)\). Prove that
  \(f:[a,b]\to\mb R\) is constant.
\end{exercise}

\begin{solution}
    Let \(P\) be the partition where \(L(f, P) = U(f, P)\). Then
    \[ 0 = U(f, P) - L(f, P) = \sum_{i=1}^{n} M_i(x_{i} - x_{i-1}) -
                                \sum_{i = 1}^{n} m_i (x_{i} - x_{i-1}) 
                            = \sum_{i=1}^{n} (M_{i} - m_{i})(x_{i} - x_{i-1}) .\]
    Since \(x_{i} > x_{i-1}\), \((x_{i} - x_{i-1}) > 0\).  Similarly,
    \((M_{i} - m_{i}) \geq 0\). This implies that the term 
    \((M_{i} - m_{i})(x_{i} - x_{i-1})\) is nonnegative, but since 
    the entire sum is zero, we must have \(M_{i} = m_{i}\) for
    all \(i \in [n]\). It follows that \(f\) takes the same value
    within each partition interval, and since 
    \([x_{i - 1}, x_{i}] \cap [x_{i}, x_{i + 1}] = \{x_{i}\}\), \(f\)
    takes the same value for all of \([a,b]\). Therefore, \(f\)
    is constant.
\end{solution}




\section{The Archimedes-Riemann Theorem}


\begin{lemma}[6.7]
  For a bounded function \(f:[a,b]\to\mb R\) and a partition \(P\) of
  \([a,b]\),
  \[
    L(f,P)
      \leq
    \underline{\int_a^b}f\leq\overline{\int_a^b}f\leq U(f,P)
  .\]
\end{lemma}

\begin{proof}
    By definition, \(\overline{\int_a^b} f \leq U(f, P)\) and
    \(L(f, P) \leq \underline{\int_a^b} f\). Then, by Lemma 6.4
    we have \(\underline{\int_a^b} f \leq \overline{\int_a^b} f\).
    The result follows.
\end{proof}


\begin{theorem}[6.8, The Archimedes-Riemann Theorem]
  Let \(f:[a,b]\to\mb R\) be a bounded function. Then \(f\) is integrable on
  \([a,b]\) if and only if there is a sequence \(\{P_n\}\) of partitions
  of the interval \([a,b]\) such that
  \[
    \lim_{n\to\infty}[U(f,P_n)-L(f,P_n)]=0
  .\]
  Moreover, for any such sequence of partitions,
  \[
    \lim_{n\to\infty} L(f,P_n)
      =
    \int_a^b f
      =
    \lim_{n\to\infty} U(f,P_n)
  .\]
\end{theorem}

\begin{proof}
    Suppose \(f\) is integrable on \([a,b]\). Then by definition
    \[ \underline{\int_a^b} f = \int_a^b f = \overline{\int_a^b} f .\]
    For convenience, let \(L = \underline{\int_a^b} f\) and
    \(U = \overline{\int_a^b} f\). Now, for each \(n \in \mb N\), 
    define \(L_n \equiv L - \frac{1}{n}\) and \(U_n \equiv U + \frac{1}{n}\).
    Since \(L\) is the supremum of the lower Darboux sums of \(f\),
    \(L_n\) is not an upper bound of this collection and so there
    exists a partition \(P'\) such that \(L_n < L(f, P')\). By similar
    reasoning, there exists a partition \(P''\) such that
    \(U(f, P'') < U_n \). Define \(P_n = P' \cup P''\) as their common
    refinement. This gives us
    \[ 0 \leq U(f, P_n) - L(f, P_n) < U_n - L_n = 
        \Bigg [ \int_a^b f + \frac{1}{n} \Bigg ] - 
        \Bigg [ \int_a^b f - \frac{1}{n} \Bigg ] = \frac{2}{n}. \]
    Hence,
    \[ \limit [ U(f, P_n) - L(f, P_n) ] = 2 \limit \frac{1}{n} = 0 \]
    and so \(\{P_n\}\) is an Archimedean sequence. 


    Conversely, suppose we had an Archimedean sequence \(\{P_n\}\) so that 
    \[ \limit [ U(f, P_n) - L(f, P_n) ] = 0 .\]
    Because 
    \[L(f, P_n) \leq \underline{\int_a^b} f \leq \overline{\int_a^b} f \leq U(f, P_n) \]
    by Lemma 6.7, we have (by taking the limit), 
    \[ 0 \leq \overline{\int_a^b} f - \underline{\int_a^b} f \leq \limit [U(f, P_n) - L(f, P_n)] = 0 .\]
    Hence \(\underline{\int_a^b} f = \overline{\int_a^b} f \) and so \(f\)
    is integrable.

    Moreover, Lemma 6.7 shows that \( 0 = \limit U(f, P_n) - \overline{\int_a^b} f \)
    and \(0 = \underline{\int_a^b} f - \limit L(f, P_n) \) and so we get
    \[ \limit L(f, P_n) = \underline{\int_a^b} f = \int_a^b f = \overline{\int_a^b} f = \limit U(f, P_n) .\]
\end{proof}


\begin{example}[6.9]
  Show that
  a monotonically increasing function \(f:[a,b]\to\mb R\) is integrable.
\end{example}

\begin{solution}
    Let \(P_n\) be the regular partition on \([a,b]\). Since \(f\) is 
    monotonically increasing, on a partition interval \([x_{i-1}, x_i]\),
    \(M_i = f(x_{i})\) and \(m_i = f(x_{i-1})\). Then
    \begin{align*}
        \limit [U(f, P_n) - L(f, P_n)] &= \limit \Bigg [ \sumi M_{i}(x_i - x_{i-1}) - \sumi m_i (x_i - x_{i-1}) \Bigg ]\\
            &= \limit \Bigg [ \sumi (M_i - m_i)(x_i - x_{i-1}) \Bigg ] \\
            &= \limit \Bigg [ \sumi (f(x_i) - f(x_{i-1})) \frac{b - a}{n} \Bigg ] \\
            &= \limit \frac{b - a}{n} \Bigg [ \sumi (f(x_i) - f(x_{i-1})) \Bigg ] \\
            &= \limit \frac{b - a}{n} (f(b) - f(a)) \\
            &= 0.
    \end{align*}
    Therefore, by Theorem 6.8, \(f\) is integrable on \([a,b]\).
\end{solution}

\begin{example}[6.11]
  Show that \(\int_0^1 x^2\,dx=\frac{1}{3}\).
\end{example}

\begin{solution}
    Since \(f(x) = x^2\) is monotonically increasing on \([0,1]\), 
    \(f\) is integrable by the above example. Let 
    \(P_{n} = \{x_{0}, x_{1}, ..., x_{n}\}\) be the regular partition 
    on \([0,1]\). Then \(x_i = \frac{i}{n}\) and using the fact that
    \(\sum_{i=1}^{n} i^2 = \frac{n(n +1)(2n+1)}{6}\), we get
    \begin{align*}
        \int_0^1 x^2, dx&= \limit U(f, P_n) \\
                        &= \limit \sumi M_i (x_i - x_{i-1}) \\
                        &= \limit \sumi f(x_{i}) (x_i - x_{i-1}) \\
                        &= \limit \sumi \frac{1}{n} \frac{i^2}{n^2} \\
                        &= \limit \frac{1}{n^3} \sumi i^2 \\
                        &= \limit \frac{1}{n^3} \Bigg [ \frac{n(n+1)(2n+1)}{6} \Bigg ]\\
                        &= \limit \frac{2n^2 + 3n + 1}{6n^2} \\
                        &= \frac{1}{3} .\\
    \end{align*}
\end{solution}

\begin{exercise}[4]
  Prove that for a natural number \(n\),
  \[ \sum_{i=1}^n i = \frac{n(n+1)}{2} .\]
  Then use this fact and the Archimedes-Riemann Theorem to show that
  \(\int_a^b x\,dx=(b^2-a^2)/2\).
\end{exercise}

\begin{solution}
    First, we prove the summation holds by induction on \(n\). If \(n = 1\),
    \(\sum_{i=1}^1 i = 1 = \frac{1(2)}{2}\). Assume this identity holds
    for all natural numbers \(k \leq n\) and now consider \(n + 1\). Then
    \begin{align*}
        \sum_{i=1}^{n+1} i &= \sum_{i = 1}^{n} i + (n + 1) \\
                        &= \frac{n(n+1)}{2} + (n + 1) \\
                        &= \frac{n^2 + 3n + 2}{2} \\
                        &= \frac{ (n+1)((n+1) + 1)}{2} \\
    \end{align*}
    and hence the induction is complete.

    We note that \(f(x) = x\) is monotonically increasing on \(\mb R\) and
    consequently integrable. Thus, for a regular partition \(P_n\) on 
    \([a,b]\), we have
    \begin{align*}
        \int_a^b x\,dx &= \limit U(f, P) \\
                       &= \limit \sumi M_i (x_i - x_{i-1}) \\
                       &= \limit \sumi x_i \frac{b - a}{n} \\
                       &= \limit \sumi \Bigg (a + i \frac{b-a}{n} \Bigg ) \frac{b-a}{n} \\
                       &= \limit \frac{b-a}{n} \Bigg [ \sumi a + \frac{b-a}{n} \sumi i \Bigg ] \\
                       &= \limit \frac{b-a}{n} \Bigg [ na + \frac{b-a}{n} \cdot \frac{n(n+1)}{2} \Bigg ] \\
                       &= \limit [(ab - a^2) + \frac{(b-a)^2 (n+1)}{2n}] \\
                       &= ab - a^2 + \frac{(b-a)^2}{2} \\
                       &= \frac{2ab - 2a^2 + b^2 - 2ab + a^2}{2} \\
                       &= \frac{b^2 - a^2}{2} .\\
    \end{align*}
\end{solution}


\begin{exercise}[6b]
  Use the Archimedes-Riemann Theorem to show that for \(0\leq a<b\),
  \[
    \int_a^b x^2\,dx = \frac{b^3-a^3}{3}
  .\]
\end{exercise}

\begin{solution}
    Generalizing from Example 6.11, 
     \begin{align*}
        \int_a^b x^2, dx&= \limit U(f, P_n) \\
                        &= \limit \sumi M_i (x_i - x_{i-1}) \\
                        &= \limit \sumi f(x_{i}) (x_i - x_{i-1}) \\
                        &= \limit \sumi \frac{b - a}{n} (a + \frac{b-a}{n} i)^2 \\
                        &= \limit \frac{b - a}{n} \Bigg [ a^2 \sumi 1 + 2a \frac{b-a}{n} \sumi i + \frac{(b-a)^2}{n^2} \sumi i^2 \Bigg ] \\ 
                        &= \limit \frac{b - a}{n} \Bigg [ na^2 + a(b - a)(n + 1) + \frac{ (n + 1)(2n + 1)(b - a)^2}{6n} \Bigg ] \\
                        &= \limit a^2 (b - a) + \limit a(b - a)^2 \frac{n+1}{n} + \limit \frac{ (2n^2 + 3n + 1) (b - a)^3}{6n^2} \\
                        &= a^2 (b - a) + a(b - a)^2 + \frac{(b - a)^3}{3} \\
                        &= \frac{1}{3} \Bigg [ (3a^2 b - 3a^3) + (3ab^2 - 6a^2 b + 3a^3) + (b^3 - 3ab^2 + 3a^2 b - a^3) \Bigg ] \\  
                        &= \frac{b^3 - a^3}{3} \\
    \end{align*}
\end{solution}


\begin{exercise}[9]
  Suppose that the functions \(f:[a,b]\to\mb R\) and
  \(g:[a,b]\to\mb R\) are integrable. Show that there is a sequence
  \(\{P_n\}\) of partitions of \([a,b]\) that is an Archimediean sequence
  of partitions for \(f\) on \([a,b]\) and also an Archimedean sequence
  of partitions for \(g\) on \([a,b]\).
\end{exercise}
\begin{solution}
    By the Archimedes-Riemann Theorem, there exists Archimedean sequences
    \(Q_n\) and \(R_n\) for \(f\) and \(g\), respectively, such that 
    \( \limit [U(f, Q_n) - L(f, Q_n)] = 0\) and \(\limit [U(g, R_n) - L(g, R_n)] = 0\).
    For each \(n\), define \(P_n = Q_n \cup R_n\). The Refinement lemma implies
    \[ 0 = \limit [U(f, Q_n) - L(f, Q_n)] \geq \limit [U(f, P_n) - L(f, P_n)] \geq 0 \]
    and 
    \[ 0 = \limit [U(g, R_n) - L(g, R_n)] \geq \limit [U(g, P_n) - L(g, P_n)] \geq 0 .\]
    Therefore, \(\{P_n\}\) is an Archimedean sequence for \(f\) and \(g\).
\end{solution}




\section{Additivity, Monotonicity, and Linearity}


\begin{theorem}[6.12, Additivity over Intervals]
  Let \(f:[a,b]\to\mb R\) be integrable on \([a,b]\) and let \(c\in(a,b)\).
  Then \(f\) is integrable on \([a,c]\) and \([c,b]\), and furthermore
  \[
    \int_a^b f = \int_a^c f + \int_c^b f
  .\]
\end{theorem}

\begin{proof}
    By the Archimedes-Riemann Theorem, there exists an Archimedean sequence
    \(Q_n\) of \(f\) on \([a,b]\). Define \(P_n = Q_n \cup \{c\}\) for
    every \(n \in \mb N\). This refinement is also an Archimedean sequence
    of \(f\) on \([a,b]\). Next, define \(R_n = P_n \cap [a, c]\) and
    \(S_n = P_n \cap [b, c]\) for every \(n \in \mb N\). Since 
    \(U(f, P_n) = U(f, R_n) + U(f, S_n)\) and \(L(f, P_n) = L(f, R_n) + L(f, S_n)\),
    we have
    \begin{align*}
        0 &= \limit [ U(f, P_n) - L(f, P_n) ] \\
          &= \limit [ (U(f, R_n) + U(f, S_n)) - (L(f, R_n) + L(f, S_n)) ] \\
          &= \limit [ U(f, R_n) - L(f, R_n) ] + \limit [ U(f, S_n) - L(f, S_n) ] .\\
    \end{align*}
    Since the terms within the limits are nonnegative, both limits go 
    to zero. Hence, \(R_n\) and \(S_n\) are Archimedean sequences of \(f\)
    on \([a,c]\) and \([c, b]\), respectively. Thus, \(f\) is integrable
    on \([a,c]\) and \([c, b]\). Moreover,
    \begin{align*}
        \int_a^b f &= \limit U(f, P_n) \\
                   &= \limit (U(f, R_n) + U(f, S_n)) \\
                   &= \limit U(f, R_n) + \limit U(f, S_n) \\
                   &= \int_a^c f + \int_c^b f . \\
    \end{align*}
\end{proof}


\begin{theorem}[6.13, Monotonicity of the Integral]
  Suppose \(f,g:[a,b]\to\mb R\) are integrable and that \(f(x)\leq g(x)\)
  for all \(x\in[a,b]\). Then
  \[
    \int_a^b f \leq \int_a^b g
  .\]
\end{theorem}

\begin{proof}
    By the Archimedes-Riemann theorem, we have Archimedean sequences 
    \(\{Q_n\}\) and \(\{R_n\}\)for \(f\) and \(g\) on \([a,b]\), respectively. 
    For each \(n \in \mb N\), define \(P_n = Q_n \cup R_n\). Since \(\{P_n\}\)
    refines both sequences, it is an Archimedean sequence of both \(f\) and \(g\)
    on \([a,b]\). Consequently,
    \begin{align*}
        \int_a^b f &= \limit U(f, P_n) \\
                   &\leq \limit U(g, P_n) \\
                   &= \int_a^b g \\
    \end{align*}
    following from the fact that \(f(x) \leq g(x)\) implies \(U(f, P) \leq U(g, P)\)
    (by definition) for any partition \(P\).
\end{proof}


\begin{lemma}[6.14]
  Let \(f,g:[a,b]\to\mb R\) be bounded and let \(P\) partition \([a,b]\).
  Then
  \[
    L(f,P)+L(g,P)\leq L(f+g,P)
      \text{~~and~~}
    U(f+g,P)\leq U(f,P)+U(g,P)
  .\]
  Moreover, for any number \(\alpha\),
  \[
    U(\alpha f,P)=\alpha U(f,P)
      \text{~~and~~}
    L(\alpha f,P)=\alpha L(f,P)
      \text{~~if~}
    \alpha\geq 0
  \]
  \[
    U(\alpha f,P)=\alpha L(f,P)
      \text{~~and~~}
    L(\alpha f,P)=\alpha U(f,P)
      \text{~~if~}
    \alpha< 0
  .\]
\end{lemma}

\begin{proof}
    Let \(B([a,b])\) be the set of bounded real functions on \([a,b]\).
    For partition \(P = \{x_0, x_1, ..., x_n\}\), denote \(I_i = [x_{i-1}, x_i]\) 
    for \(i \in [n]\). Then, define functions: 
    \[M_i, m_i : B([a,b]) \rightarrow \mb R \word{by}\]
    \[M_i = \sup \{ h(x) | x \in I_i \} \word{and} m_i = \inf \{ h(x) | x \in I_i \} . \]
    Then, for all \(x \in I_i\), we have
    \[ m_i(f) + m_i(g) \leq f(x) + g(x) \leq M_i(f) + M_i(g) .\]
    This shows that \(m_i(f) + m_i(g)\) is a lower bound of \(f + g\) on \(I_i\),
    and similarly for \(M_i(f) + M_i(g)\) (upper bound). Hence, by definition, and
    noting that the pointwise sum of bounded functions is bounded, we get
    \[ m_i(f) + m_i(g) \leq m_i(f + g) \word{and} M_i(f + g) \leq M_i(f) + M_i(g) .\]
    Therefore, this implies that 
    \[ L(f, P) + L(g, P) \leq L(f+g, P) \word{and} U(f + g, P) \leq U(f, P) + U(g, P) .\]

   Next, by Exercise 4, we know that 
   \[ M_i(\alpha f) = \alpha M_i(f) \word{and} m_i(\alpha f) = \alpha m_i(f) \word{if} \alpha \geq 0 \]
   and so \(U(\alpha f, P) = \alpha U(f, P)\) and \(L(\alpha f, P) = \alpha L(f, P) \).
   Likewise,
   \[ M_i(\alpha f) = \alpha m_i(f) \word{and} m_i(\alpha f) = \alpha M_i(f) \word{if} \alpha \leq 0 \]
   and thus \(U(\alpha f, P) = \alpha L(f, P)\) and \(L(\alpha f, P) = \alpha U(f, P) \).
\end{proof}


\begin{theorem}[6.15, Linearity of the Integral]
  Let \(f,g:[a,b]\to\mb R\) be integrable. Then for any two numbers
  \(\alpha,\beta\), the function \(\alpha f+\beta g:[a,b]\to\mb R\) is
  integrable and
  \[
    \int_a^b[\alpha f+\beta g]=\alpha\int_a^b f + \beta\int_a^b g
  .\]
\end{theorem}

\begin{proof}
    It suffices to show two things: first, for any integrable function 
    \(h: [a,b] \to \mb R\) and any number \(\alpha\), the function 
    \(\alpha h\) is integrable on \([a,b]\) and 
    \[ \int_a^b \alpha h = \alpha \int_a^b h .\]
    Second, for integrable functions \(f, g\) on \([a,b]\), the function
    \(f + g\) is integrable and 
    \[ \int_a^b [f + g] = \int_a^b f + \int_a^b g .\]
    From these, we get
    \begin{align*} 
        \int_a^b[ \alpha f + \beta g ] &= \int_a^b \alpha f + \int_a^b \beta g \\
                                       &= \alpha \int_a^b f + \beta \int_a^b g .\\
    \end{align*}


    We now prove the first fact. Let \(\{P_n\}\) be an Archimedean sequence
    of \(h\). Applying the previous lemma, regardless of the
    value of \(\alpha\) we have
    \[ U(\alpha h, P_n) - L(\alpha h, P_n) = |\alpha| [U(h, P_n) - L(h P_n)] \]
    and so taking the limit tells us that \(\{P_n\}\) is an Archimedean 
    sequence of \(\alpha h\). Now, for \(\alpha \geq 0\),
    \[ \int_a^b \alpha h = \limit U(\alpha h, P_n) = \alpha \limit U(h, P_n) = \alpha \int_a^b h\]
    while for \(\alpha \leq 0\),
    \[ \int_a^b \alpha h = \limit U(\alpha h, P_n) = \alpha \limit L(h, P_n) = \alpha \int_a^b h .\]
    This gives us our result.


    Now we prove the second fact. From the proof of Theorem 6.13, we know
    there exists an Archimedean sequence \(\{P_n\}\) common to both \(f\)
    and \(g\). Then, applying the previous lemma, we get
    \begin{align*}
        0 &\leq  \limit [ U(f + g, P_n) - L(f + g, P_n) ] \\ 
          &\leq \limit [ [U(f, P_n) + U(g, P_n)] - [L(f, P_n) + L(g, P_n)]] \\
          &= \limit [U(f, P_n) - L(f, P_n)] + \limit [U(g, P_n) - L(g, P_n)] \\
          &= 0 .
    \end{align*}
    This shows that \(\{P_n\}\) is an Archimedean sequence of \(f+g\). It follows
    that
    \begin{align*} 
        \int_a^b f + \int_a^b g &= \limit U(f, P_n) + \limit U(g, P_n) \\
                                &= \limit [U(f, P_n) + U(g, P_n)] \\
                                &\geq \limit [U(f + g, P_n)] \\
                                &= \int_a^b [f + g] \\
                                &= \limit [ L(f + g, P_n) ] \\
                                &\geq \limit [L(f, P_n) + L(g, P_n) ] \\
                                &= \limit L(f, P_n) + \limit L(g, P_n) \\
                                &= \int_a^b f + \int_a^b g \\
    \end{align*}
    and so \(\int_a^b [f + g] = \int_a^b f + \int_a^b g \).

\end{proof}


\begin{exercise}[1]
  Suppose that the functions \(f,g,f^2,g^2,fg\) are integrable on \([a,b]\).
  Prove that \((f-g)^2\) is also integrable on \([a,b]\) and that
  \(\int_a^b(f-g)^2\geq0\). Use this to prove that
  \[
    \int_a^b fg
      \leq
    \frac{1}{2}\left[
      \int_a^b f^2 + \int_a^b g^2
    \right]
  .\]
\end{exercise}

\begin{solution}
    Since \((f - g)^2 = f^2 - 2fg + g^2\) and each term on the RHS
    is integrable, by linearity, \((f-g)^2\) is integrable. Also,
    since \((f - g)^2 \geq 0\) (the zero function) and \(\int_a^b 0 = 0\),
    we have from the monotonicity property that
    \[ \int_a^b f^2 - 2 \int_a^b fg + \int_a^b g^2 = \int_a^b (f - g)^2 \geq \int_a^b 0 = 0 .\]
    Hence, \( \int_a^b f^2 + \int_a^b g^2 \geq 2 \int_a^b fg \) and thus
    \[ \frac{1}{2} \left[ \int_a^b f^2 + \int_a^b g^2 \right] \geq \int_a^b fg .\] 
\end{solution}

\begin{exercise}[4]
  Suppose that \(S\) is a nonempty bounded set of numbers and that \(\alpha\)
  is a number. Define \(\alpha S\) to be the set \(\{\alpha x:x\in S\}\).
  Prove that
  \[
    \sup\alpha S=\alpha\sup S
      \text{~~and~~}
    \inf\alpha S=\alpha\inf S
      \text{~~if~}
    \alpha\geq 0
  \]
  while
  \[
    \sup\alpha S=\alpha\inf S
      \text{~~and~~}
    \inf\alpha S=\alpha\sup S
      \text{~~if~}
    \alpha< 0
  .\]
\end{exercise}

\begin{solution}
    Since \(S\) is a nonempty, bounded set of real numbers, \(b = \sup S\)
    exists by the Completeness Axiom. Next, because \(\alpha\) is a fixed nonnegative
    number, \(\alpha S\) is also nonempty and bounded and so a supremum for this
    set exists. Claim: \( \sup \alpha S = \alpha b \). In the case where \(\alpha = 0\),
    then \(\alpha S = \{0\}\) and so \(\sup \alpha S = 0 = \alpha \sup S\),
    trivially. Otherwise, if \(\alpha > 0\), note that \(b \geq s \) for all \(s \in S\)
    and so \(\alpha b \geq \alpha s\). Since all elements of \(\alpha S\) take the 
    form of \(\alpha s\) for some \(s \in S\), we have that \(\alpha b\) is an upper 
    bound of \(\alpha S\). Now suppose that we have \(\alpha b > x\). 
    Dividing by \(\alpha\), we get \(b > \alpha^{-1} x \). Then, by definition,
    \(\alpha^{-1} x\) is not an upper bound of \(S\) and so there exists \(u \in S\)
    such that \(b \geq u > \alpha^{-1} x\). This implies
    \[ \alpha b \geq \alpha u > x \]
    and so \(x\) cannot be an upper bound of \(\alpha S\). Thus, \(\alpha b = \sup \alpha S\).

    Last, consider when \(\alpha < 0\) and let \(c = \inf S\). For all \(s \in S\),
    \(s \geq c\) and so multiplying by \(\alpha\) gives us \(\alpha s \leq \alpha c\). 
    By our earlier reasoning \(\alpha c\) is an upper bound of \(\alpha S\), so
    suppose \(\alpha c > x\). Divide by \(\alpha\) to get \(c < \alpha^{-1}x\).
    By definition of the infimum, there exists \(v \in S\) so that
    \(v < \alpha^{-1}x\). Multiplying by \(\alpha\) yields \(\alpha v > x \)
    and so \(x\) cannot be an upper bound of \(\alpha S\). Thus, \(\sup \alpha S = \alpha c\).

    Repeat all of the above with the set \(-S\) and note that \(\sup -S = \inf S\)
    to derive the equalities for the infimums of \(\alpha S\).
\end{solution}


\begin{exercise}[6]
  Suppose that \(f:[a,b]\to\mb R\) is bounded and let \(a<c<b\). Prove that if
  \(f\) is integrable on both \([a,c],[c,b]\), then it is integrable on
  \([a,b]\).
\end{exercise}

\begin{solution}
    By assumption, there exists Archimedean sequences \(\{Q_n\}\) and \(\{R_n\}\) on
    \([a, c]\) and \([c, d]\), respectively, such that \(\limit U(f, Q_n) = \int_a^c f\)
    and \(\limit U(f, R_n) = \int_c^b f\). For each \(n \in \mb N\), define the
    set \(P_n : Q_n \cup R_n\) (with say \(Q_n = \{q_0, ..., q_k\}\) and 
    \(R_n = \{r_0, ..., r_m\}\)). Then \(p_0 = q_0 = a\), \(p_k = q_k = c = r_0\),
    and \(p_{k+m} = r_m = b\) and since \(Q_n \cap R_n = \{c\}\), \(P_n\) is 
    a partition of \([a,b]\). Next, note that \(U(f, P_n) = U(f, Q_n) + U(f, R_n)\)
    and \(L(f, P_n) = L(f, Q_n) + L(f, R_n)\). It then follows that
    \begin{align*}
        \limit [ U(f, P_n) - L(f, P_n) ] &= \limit [ (U(f, Q_n) + U(f, R_n) - (L(f, Q_n) + L(f, R_n) ] \\
                &= \limit [U(f, Q_n) - L(f, Q_n)] + \limit [U(f, R_n) - L(f, R_n)] \\
                &= 0 + 0 \\
                &= 0 \\
    \end{align*}
    and so \(\{P_n\}\) is an Archimedean sequence. Therefore, \(f\) is integrable on \([a,b]\).
\end{solution}




\section{Continuity and Integrability}


\begin{lemma}[6.17]
  Let the function \(f:[a,b]\to\mb R\) be continuous let \(P\) partition
  its domain. Then there is a partition interval of \(P\) that contains two
  points \(u,v\) for which the following estimate holds:
  \[
    0
      \leq
    U(f,P)-L(f,P)
      \leq
    [f(v)-f(u)][b-a]
  .\]
\end{lemma}

\begin{proof}
    Let \(P = \{x_0, x_1, ..., x_n\}\) be a partition of \([a,b]\). For
    \(i \in [n]\), consider the restriction of \(f\) to \([x_{i-1}, x_i]\).
    Since \(f\) is continuous, so is its restriction. Morever, the partition
    interval is a closed, bounded interval. Thus, by the Extreme value theorem,
    there exists points \(u_i, v_i \in [x_{i-1}, x_i]\) such that
    \(f(u_i) = \min f([x_{i-1}, x_i])\) and \(f(v_i) = \max f([x_{i-1}, x_i])\).
    Now let \[k = \word{argmax}_{i \in [n]} \{ f(v_i) - f(u_i) \} \]
    and set \(u = u_k\) and \(v = v_k\). Hence,
    \begin{align*}
        0  &\leq U(f, P) - L(f, P) \\
           &= \sumi (M_i - m_i)(x_i - x_{i-1}) \\
           &= \sumi (f(v_i) - f(u_i))(x_i - x_{i-1}) \\
           &\leq \sumi (f(v) - f(u))(x_i - x_{i-1}) \\
           &= [f(v) - f(u)] \sumi (x_i - x_{i-1}) \\
           &= [f(v) - f(u)] [b - a] \\
    \end{align*}
\end{proof}


\begin{theorem}[6.18]
  A continuous function on a closed bounded interval is integrable.
\end{theorem}

\begin{proof}
    Let \(f\) be a continuous function on \([a,b]\), and
    let \(\{P_n\}\) be a sequence of partitions where \(\limit \text{gap~} P_n = 0\)
    (for instance, regular partitions). For each \(n \in \mb N\),
    apply the preceding lemma to obtain points \(u_n\) and \(v_n\). Since the two points
    belong to the same partition interval, we have \(|v_n - u_n| \leq \text{gap~} P_n\).
    It follows that
    \[ 0 = \limit - \text{gap~} P_n \leq \limit [v_n - u_n] \leq \limit \text{gap~} P_n = 0. \]
    Next, we note that a continuous function on a closed, bounded interval
    is uniformly continuous and consequently, \(\limit [f(v_n) - f(u_n)] = 0\).
    By the previous lemma,
    \[ 0 \leq \limit [ U(f, P_n) - L(f, P_n)] \leq \limit [f(v_n) - f(u_n)][b - a] = 0 \]
    and so \(\{P_n\}\) is an Archimedean sequence of \(f\). Thus, \(f\)
    is integrable.
\end{proof}


\begin{theorem}[6.19]
  Suppose \(f:[a,b]\to\mb R\) is bounded on \([a,b]\) and continuous on
  \((a,b)\). Then \(f\) is integrable on \([a,b]\) and the value of
  \(\int_a^b f\) does not depend on the values of \(f\) at the endpoints
  of \([a,b]\).
\end{theorem}

\begin{proof}
    Construct sequences \(\{a_n\}\) and \(\{b_n\}\) such that 
    \[ a < a_n < b_n < b \word{for all} n ,\]
    \(\limit a_n = a\), and \(\limit b_n = b\). For each \(n \in \mb N\),
    the restriction of \(f\) to \([a_n, b_n]\) is continuous and hence
    integrable. This means there exists a corresponding Archimedean
    sequence and so we can choose a partition \(P_n^*\) of \([a_n, b_n]\)
    such that 
    \[ 0 \leq U(f, P_n^*) - L(f, P_n^*) \leq \frac{1}{n} \]
    (by definition of the limit of a sequence). We then define
    \(P_n = P_n^* \cup \{a, b\}\) so that \(P_n\) is a partition of 
    \([a,b]\). Let \(A_n = U(f, \{a, a_n\}) - L(f, \{a, a_n\})\)
    and \(B_n = U(f, \{b_n, b\}) - L(f, \{b_n, b\})\). Then
    \[ U(f, P_n) - L(f, P_n) = U(f, P_n^*) - L(f, P_n^*) + A_n + B_n .\]

    Because \(f\) is bounded, there exists \(M\) such that
    \(-M \leq f(x) \leq M\) for \(x \in [a,b]\). Consequently, by Lemma 6.1,
    \[ 0 \leq A_n \leq [M - (-M)][a_n - a] = 2M[a_n - a] \word{and} 0 \leq B_n \leq 2M[b_n - b] .\]
    
    This means that 
    \[ 0 \leq U(f, P_n) - L(f, P_n) \leq [U(f, P_n^*) - L(f, P_n^*)] + 2M[a_n - a] + 2M[b_n - b] .\]

    Since we know that 
    \[0 \leq \limit [U(f, P_n^*) - L(f, P_n^*)] \leq \limit \frac{1}{n} = 0 ,\]
    \(\limit [a_n - a] = 0\), and \(\limit [b_n - b] = 0\), we get
    \[ \limit [U(f, P_n) - L(f, P_n)] = 0 .\]

    Therefore, \(\{P_n\}\) is an Archimedean sequence for \(f\) on \([a,b]\),
    and \(f\) is integrable.

    
    Moreover, 
    \[ \limit [ U(f, P_n) - U(f, P_n^*) ] = \limit [ U(f, \{a, a_n\}) +  U(f, \{b_n, b\}) ] \leq \limit M[a_n - a] + \limit M[b_n - b] = 0 .\]
    Thus,
    \[ \int_a^b f = \limit U(f, P_n) = \limit U(f, P_n^*) \]
    and so the integral is indepedent of the values of \(f(a)\) and \(f(b)\).

\end{proof}

\begin{exercise}[1]
  Determine whether each of the following statements is true or false, and
  justify your answer.
  \begin{enumerate}[(a)]
    \item If \(f:[a,b]\to\mb R\) is integrable and \(\int_a^b f=0\), then
      \(f(x)=0\) for all \(x\in[a,b]\).
    \item If \(f:[a,b]\to\mb R\) is integrable, then \(f\) is continuous.
    \item If \(f:[a,b]\to\mb R\) is integrable and \(f(x)\geq0\) for all
      \(x\in[a,b]\), then \(\int_a^b f\geq 0\).
    \item A continuous function \(f:(a,b)\to\mb R\) defined on an open interval
      \((a,b)\) is bounded.
    \item A continuous function \(f:[a,b]\to\mb R\) defined on a closed interval
      \([a,b]\) is bounded.
  \end{enumerate}
\end{exercise}
\begin{solution}
  \begin{enumerate}[(a)]
    \item False. Define \(f\) to be identically zero on \((a,b)\) and
          \(f(a) = f(b) = 1\). Then \(f\) on \([a,b]\) is not identically zero,
          but \(\int_a^b f = 0\) by Theorem 6.19.
    \item False. Define \(f: [a, b] \rightarrow \mb R\) by
         \[ f(x) = \begin{cases} 
                 0 &\word{if} x \leq (b - a)/2 \\
                 1 &\word{if} x > (b - a)/2 \\
             \end{cases} \]
         Since \(f\) is monotonically increasing, it is integrable. However,
         \(f\) is not continuous at \(x = 1/2\).
    \item True. Since \(f(x) \geq 0(x) = 0\) on \([a,b]\), by monotonicity,
        \[ \int_a^b f \geq \int_a^b 0 = 0 .\]
    \item False. The function \(f(x) = 1/x\) on \((0,1)\) is continuous but
        not bounded above. Indeed, suppose there exists a number \(M > 0\)
        such that \(M \geq f(x)\) within this interval. Choose any point
        greater than \(1 / M\) for the contradiction.
    \item True. This is a consequence of the Extreme value theorem.
  \end{enumerate}
\end{solution}


\begin{exercise}[5]
  Suppose that the continuous function \(f:[a,b]\to\mb R\) has the property
  \[
    \int_c^d f\leq 0
      \text{~~whenever~}
    a\leq c<d\leq b
  .\]
  Prove that \(f(x)\leq 0\) for all \(x\in[a,b]\). Is this true if we only
  require integrability of the function?
\end{exercise}

\begin{solution}
    Suppose on the contrary that there exists \(x \in [a,b]\) such that
    \(f(x) > 0\). Since \(f\) is continuous, \(f\) obtains a maximum \(f(x_0)\)
    by the Extreme value theorem. By our assumption, it follows that 
    \(f(x_0) > 0\). Now let \(\epsilon = f(x_0)\) so that, by continuity,
    there exists \(\delta > 0\) such that 
    \[ |x - x_0| < \delta \word{implies} |f(x_0) - 0| < \epsilon .\]
    This implies that we can find an open neighborhood \(I\) contained
    in \([a,b]\) such that \(x \in I\) implies \(f(x) > 0\). (Even
    in the case where \(x_0\) is an endpoint, we can simply omit
    \(x_0\) from consideration  and use the remaining open interval).
    Consequently, \(f\) is integrable on \(I\) (by Theorem 6.19) 
    and its integral is positive (by monotonicity). However, since 
    the bounds of \(I\) are within \([a,b]\), we contradict the 
    property that \(\int_c^d f \leq 0\) whenever \(a \leq c < d \leq b\).
    Hence, \(f(x) \leq 0\) for all \(x \in [a,b]\).

    Clearly, the statement becomes false if we only require the
    integrability of \(f\). For instance, define \(f:[0,1] \rightarrow \mb R\)
    by \[ f(x) = \begin{cases} 1  &\word{if} x < 1/3 \\
                              -1 &\word{if} x \geq 1/3 \\
                \end{cases}. \]
    Then, \(\int_0^1 f = -\frac{1}{3} \leq 0 \) but not all
    \(f(x) \leq 0\).
\end{solution}


\begin{exercise}[6]
  Suppose that \(f:[0,1]\to\mb R\) is continuous and that \(f(x)\geq 0\) for
  all \(x\in[0,1]\). Prove that \(\int_0^1 f>0\) if and only if there is a
  point \(x_0\in[0,1]\) at which \(f(x_0)>0\).
\end{exercise}

\begin{solution}
    We'll prove the contrapositives of the equivalency:
    \[ \int_0^1 f \leq 0 \Leftrightarrow \word{for all} x \in [a,b], f(x) \leq 0 \]
    
    By assumption, \(f(x) \geq 0\) for all \(x \in [0, 1]\)
    implies \(\int_0^1 f \geq 0\). Hence, if we suppose that
    \(\int_0^1 f \leq 0\), then \(\int_0^1 f = 0\), which can
    only happen if \(f(x) = 0\) for all \(x \in [a,b]\). This
    clearly means \(f(x) \leq 0 \) for all \(x \in [a,b]\).
    The converse follows from monotonicity.
\end{solution}




\section{The First Fundamental Theorem: Integrating Derivatives}


\begin{lemma}[6.21]
  Suppose \(f:[a,b]\to\mb R\) is integrable and that the number \(A\) has
  the property that for every \(P\) partitioning \([a,b]\),
  \[
    L(f,P) \leq A \leq U(f,P)
  .\]
  Then
  \[
    \int_a^b f = A
  .\]
\end{lemma}

\begin{proof}
    By assumption, \(A\) is a lower bound for \(\{U(f, P)\}_P\)
    and an upper bound for \(\{L(f, P)\}_P\) and so by definition
    \[ \underline{\int_a^b f} \leq A \leq \overline{\int_a^b f} .\]
    But since \(f\) is integrable, 
    \[ \underline{\int_a^b f} = \int_a^b f = \overline{\int_a^b f} \]
    and so 
    \[\underline{\int_a^b f } = \int_a^b f \leq A \leq \int_a^b f = \overline{\int_a^b f} \] 
    implies \(\int_a^b f = A\).
\end{proof}


\begin{theorem}[6.22, The First Fundamental Theorem: Integrating Derivatives]
  Let \(F:[a,b]\to\mb R\) be continuous on \([a,b]\) and differentiable on
  \((a,b)\). Moreover, suppose that its derivative
  \(F':(a,b)\to\mb R\) is both continuous and bounded. Then
  \[
    \int_a^b F'(x)~dx
      =
    F(b)-F(a)
  .\]
\end{theorem}

\begin{proof}
    We must show two things: (1) that the integral exists, and (2) that it
    is equal to \(F(b) - F(a)\). First, any extension of \(F'\) to \([a,b]\)
    remains continuous on \((a,b)\) and bounded on \([a,b]\). Thus, by Theorem
    6.19, any extension of \(F'\) is integrable. Further, every such integral
    has the same value and so \(\int_a^b F'\) is unambiguously defined for
    our original \(F'\).
    
    Second, we show that for every partition \(P = \{x_0, x_1, ..., x_n\}\) 
    of \([a,b]\),
    \[ L(F', P) \leq F(b) - F(a) \leq U(F', P) .\]
    For \(i \in [n]\), the restriction of \(F\) to \([x_{i-1}, x_i]\) is
    continuous on this closed interval, and differentiable on \((x_{i-1}, x_i)\).
    Hence, by the Mean Value Theorem, there exists a point \(c_i \in (x_{i-1}, x_i)\)
    so that 
    \[ F(x_i) - F(x_{i-1}) = F'(c_i)(x_i - x_{i-1}) .\]
    Consequently, \(m_i \leq F'(c_i) \leq M_i\) (where \(m_i\) and \(M_i\) are the infimum
    and supremum of the restriction of \(F'\), respectively). Then, multiplying this 
    inequality by \(x_i - x_{i-1}\) yields
    \[ m_i (x_i - x_{i-1}) \leq F'(c_i)(x_i - x_{i-1}) = F(x_i) - F(x_{i-1}) \leq M_i (x_i - x_{i-1}) .\]
    Taking the sum across all partition intervals, we have
    \[ L(F', P) = \sumi m_i(x_i - x_{i-1}) \leq \sumi [F(x_i) - F(x_{i-1}) ] = F(b) - F(a) \leq \sumi M_i (x_i - x_{i-1}) = U(F', P) \] 
    Thus, by the previous lemma
    \[ \int_a^b F'(x) dx = F(b) - F(a) .\]
\end{proof}


\begin{exercise}[1]
  Let \(m,b\) be positive numbers. Find the value of \(\int_0^1 mx+b ~dx\)
  in the following three ways:
  \begin{enumerate}[(a)]
    \item Using elementary geometry, interpreting the integral as an area.
    \item Using upper and lower Darboux sums based on regular partitions of
      the interval \([0,1]\) and using the Archimedes-Riemann Theorem.
    \item Using the First Fundamental Theorem (Integrating Derivatives).
  \end{enumerate}
\end{exercise}

\begin{solution}
    \begin{enumerate}[(a)]
        \item Geometrically, the area between \(mx + b\) and the x-axis consists
              of two shapes: a rectangular base and a triangle on top. The area
              of the rectangle is \[A_r = l \times w = 1 \times b = b\] and the area
              of the triangle is 
              \[ A_t = \frac{1}{2} b \times h = \frac{1}{2}(1 \times (m + b - b)) = \frac{1}{2} m .\]
              Consequently,
              \[ \int_0^1 mx + b ~dx = A_r + A_t = b + \frac{1}{2} m .\]
        \item The function \(f(x) = mx + b\) is monotonically increasing on \([0,1]\) 
              and therefore integrable by the Archimedes-Riemann Theorem. Using a sequence
              of regular partitions, we get
              \begin{align*}
                  \int_0^1 mx + b ~dx &= \limit U(f, P_n)\\
                                      &= \limit \sumi M_i \frac{1}{n} \\
                                      &= \limit \sumi (mx_i + b) \frac{1}{n} \\
                                      &= \limit [ m \sumi \frac{i}{n^2} + \frac{b}{n} \sumi 1 ] \\
                                      &= \limit [ m \frac{(n+1)}{2n} + b ] \\
                                      &= \frac{1}{2}m + b \\
              \end{align*}

          \item By linearity, \[\int_0^1 mx + b ~dx  = m \int_0^1 x ~dx + b \int_0^1 1 ~dx .\]
                Clearly, \(x\) and \(1\) are continuous and bounded on \([0, 1]\). Furthermore,
                we know that \(\frac{d}{dx} \frac{x^2}{2} = x\) and \(\frac{d}{dx} x = 1\). Thus,
                by the First Fundamental Theorem of Calculus
                \[ \int_0^1 x ~dx = \frac{1^2}{2} - \frac{0^2}{2} = \frac{1}{2} \]
                and
                \[ \int_0^1 1 ~dx = 1 - 0 = 1 .\]
                Putting it altogether, we get
                \[ \int_0^1 mx + b ~dx = m \int_0^1 x ~dx + b \int_0^1 1 ~dx = m \frac{1}{2} + b .\]
    \end{enumerate}
\end{solution}


\begin{exercise}[5]
  The monotonicity property of the integral implies that if the functions
  \(g,h:[0,\infty)\to\mb R\) are continuous and \(g(x)\leq h(x)\) for all
  \(x\geq 0\), then
  \[
    \int_0^x g\leq \int_0^x h
    \text{~~ for all~} x\geq 0
  .\]
  Use this and the First Fundamental Theorem to show that each of the following
  inequalities implies the next:
  \[
    \cos x \leq 1
    \text{~~ if~} x\geq 0
  .\]
  \[
    \sin x \leq x
    \text{~~ if~} x\geq 0
  .\]
  \[
    1-\cos x \leq \frac{x^2}{2}
    \text{~~ if~} x\geq 0
  .\]
  \[
    x-\sin x \leq \frac{x^3}{6}
    \text{~~ if~} x\geq 0
  .\]
  \[
    x-\frac{x^3}{6} \leq \sin x \leq x
    \text{~~ if~} x\geq 0
  .\]

  (For this problem, you may assume that the sine and cosine functions
  are differentiable functions with the properties
  \(\sin(0)=0\), \(\cos(0)=1\), \(\frac{d}{dx}[\sin(x)]=\cos(x)\),
  and \(\frac{d}{dx}[\cos(x)]=-\sin(x)\).)
\end{exercise}
\begin{solution}

\end{solution}

\begin{solution}
    By assumption (of the first inequality), \(\text{cos~}x\) is bounded
    on \([0, \infty)\). We also know that it is continuous. Moreover,
    we know that \(\frac{d}{dx} \text{sin~} x = \text{cos~} x\) on \(\mb R\), and
    that \(\text{sin}(0) = 0\). These facts, combined with knowing that
    \(\frac{d}{dx} x^n = nx^{n-1}\) for \(n \geq 1\), we get
    \[ \text{sin}(x) = \text{sin}(x) - \text{sin}(0) = 
            \int_0^x \text{cos~} x ~dx \leq  \int_0^x 1 ~dx = x \]
    for \(x \geq 0\). 

    Next, since \(\text{sin}(x + 2\pi) = \text{sin}(x)\) for \(x \in \mb R\) and
    \(\text{sin}(x)\) is continuous on \([0, 2\pi]\), \(\text{sin}(x)\) is 
    bounded on \([0, 2\pi]\) (by the Extreme Value Theorem), and consequently,
    \(\text{sin}(x)\) is bounded on \([0, \infty)\). We know that
    \(\frac{d}{dx} -\text{cos}(x) = \text{sin}(x) \). Hence, we can apply the
    first Fundamental Theorem of Calculus to obtain
    \[ 1 - \text{cos}(x) = [ -\text{cos}(x) - (-\text{cos}(0)) ] 
        = \int_0^x \text{sin~} x ~dx \leq \int_0^x x ~dx 
    = \frac{x^2}{2} - \frac{0^2}{2} = \frac{x^2}{2} \]
    for \(x \geq 0\).

    And again
    \[ x - \text{sin}(x) = \int_0^x [x - \text{sin}(x) ] ~ dx \leq \int_0^x \frac{x^2}{2} ~ dx = \frac{1}{2}[\frac{x^3}{3}] = \frac{x^3}{6}. \]

    Rearranging this inequality with the second inequality gives us
    \[ x - \frac{x^3}{6} \leq \text{sin~} x \leq x \]
    for \(x \geq 0\).
\end{solution}


\section{The Second Fundamental Theorem: Differentiating Integrals}


\begin{theorem}[6.26, The Mean Value Theorem for Integrals]
  Suppose that \(f:[a,b]\to\mb R\) is continuous. Then there is a point \(x_0\)
  in the interval \([a,b]\) at which
  \[
    \frac{1}{b-a}\int_a^b f
      =
    f(x_0)
  .\]
\end{theorem}

\begin{proof}
    Because \(f\) is continuous on \([a,b]\), by the Extreme value theorem, 
    there exists points \(x_m, x_M \in [a,b]\) at which \(f\) obtains its 
    minimum and maximum, respectively. In other words,
    \[ f(x_m) \leq f(x) \leq f(x_M) \]
    for all \(x \in [a,b]\). Applying the monotonicity property of integrals yields
    \[ f(x_m)(b - a) = \int_a^b f(x_m) ~dx \leq \int_a^b f(x) ~dx \leq \int_a^b f(x_M) ~dx = f(x_M)(b - a) .\]
    Dividing by \(b - a\), we get
    \[ f(x_m) \leq \frac{1}{b - a} \int_a^b f(x) ~dx \leq f(x_M) .\]
    And so, by the Intermediate value theorem, there exists a point \(x_0 \in (x_m, x_M)\)
    such that \(\frac{1}{b-a} \int_a^b f = f(x_0) \).
\end{proof}


\begin{proposition}[6.27]
  Suppose that the function \(f:[a,b]\to\mb R\) is integrable. Define
  \[
    F(x) = \int_a^x f
    \text{~~for all~} x\in[a,b]
  .\]
  Then the function \(F:[a,b]\to\mb R\) is continuous.
\end{proposition}

\begin{proof}
    Since \(f\) is integrable on \([a,b]\), then by additivity, 
    \(f\) is integrable on \([a,x]\) for \(x \in [a,b]\). This
    means that \(F\) is defined on \([a,b]\). Now, \(f\) is bounded
    (since it is integrable) and so choose \(M > 0\) such that
    \( |f(x)| \leq M\) for \(x \in [a,b]\). We will show that \(F\)
    satisfies the Lipschitz condition, which implies continuity:
    \[ |F(u) - F(v)|  \leq M |u - v| \]
    for all points \(u, v \in [a,b]\). And so, let \(u, v \in [a,b]\)
    with \(u < v\). Then by additivity,
    \[ F(v) = \int_a^v f = \int_a^u f + \int_u^v f = F(u) + \int_u^v f \]
    so that
    \[ F(v) - F(u) = \int_u^v f .\]
    Then, by Lemma 6.1 (or by monotonicity...it really doesn't matter), we get
    \[ -M(v - u) \leq \int_u^v f = F(v) - F(u) \leq M(v - u) \]
    so that
    \[ |F(v) - F(u)| \leq M|u - v|. \]
    And therefore, using the \(\epsilon-\delta\) definition of continuity
    with \(\delta = \epsilon/ M\), \(F\) is continuous on \([a,b]\).
\end{proof}


\begin{theorem}[6.29, The Second Fundamental Theorem: Differentiating Integrals]
  Suppose that \(f:[a,b]\to\mb R\) is continuous. Then
  \[
    \frac{d}{dx}\left[\int_a^x f \right]
      =
    f(x)
    \text{~~for all~} x\in(a,b)
  .\]
\end{theorem}

\begin{proof}
    Define for \(x \in [a,b]\) the function 
    \[ F(x) \equiv \int_a^x f . \]
    By the previous proposition, \(F\) is defined on \([a,b]\) and continuous.
    It then suffices to show that
    \[ \lim_{x \to x_0} \frac{F(x) - F(x_0)}{x - x_0} = f(x_0) .\]
    So let \(x \in (a,b)\) be different from \(x_0\). By additivity,
    \[ F(x) = \int_a^x f = \int_a^{x_0} f + \int_{x_0}^x f = F(x_0) + \int_{x_0}^x f \]
    if \(x_0 < x\) so that \(F(x) - F(x_0) = \int_{x^0}^x f \).
    Similarly, \(F(x) - F(x_0) = - \int_{x^0}^x f \) if \(x < x_0\). Then,
    by the Mean value theorem for integrals, there exists a point \(c\) between \(x\) and \(x_0\)
    \[ \frac{1}{x - x_0} \int_{x_0}^x f = \frac{F(x) - F(x_0)}{x - x_0} = f(c) .\]
    
    By this reasoning, we construct a sequence \(\{x_n\}\) so that \(\limit x_n = x_0\).
    Then, we construct another sequence \(\{c_n\}\) as the points chosen from
    the MVT so that \(\limit c_n = x_0\), or equivalently, \(\lim_{x \to x_0} c_x = x_0\).
    Consequently, by the continuity of \(f\),
    \[ F'(x_0) = \lim_{x \to x_0} \frac{F(x) - F(x_0)}{x - x_0} = \lim_{x \to x_0} f(c_x) = f(x_0) .\]
\end{proof}


\begin{exercise}[2b]
  Suppose \(f:[0,2]\to\mb R\) is defined by
  \[
    f(x) =
    \begin{cases}
      x^2 & \text{if } 0\leq x\leq 1 \\
      x   & \text{if } 1< x\leq 2
    \end{cases}
  .\]
  Define
  \[
    F(x)=\int_a^x f(t)~dt
    \text{~~for all~} x\in[a,b]
  \]
  and find a formula for \(F(x)\) which does not involve integrals.
\end{exercise}

\begin{solution}
    If \(x \in [0,1]\), by the First Fundamental Theorem of Calculus (FTC),
    \[ F(x) = \int_0^x t^2 ~dt = \frac{x^3}{3} - \frac{0^3}{3} = \frac{x^3}{3} . \] 
    Otherwise, if \(x \in [1,2]\), then
    \[ F(x) = F(1) + \int_1^x t ~dt = \frac{1}{3} + [ \frac{x^{2}}{2} - \frac{1^2}{2} ] 
        = \frac{x^{2}}{2} - \frac{1}{6} .\]
    Notice that when \(x = 1\), both pieces of \(F\) agree. Thus,
    \[ F(x) = \begin{cases}
                    \frac{x^{3}}{3} &\text{if } x \in [0, 1] \\
                    \frac{x^{2}}{2} - \frac{1}{6} &\text{if } x \in [1, 2] \\
              \end{cases} .\]
\end{solution}


\begin{exercise}[5]
  Suppose \(f:\mb R\to\mb R\) is continuous. Define
  \[
    G(x)
      =
    \int_0^x (x-t)f(t)~dt
    \text{~~for all~} x
  .\]
  Prove that \(G''(x)=f(x)\) for all \(x\).
\end{exercise}

\begin{solution}
    Since \(f\) is continous, \(f\) is integrable so let \(F(x) = \int_0^x f(t) ~dt\). 
    Then because \( (x-t)f(t) = xf(t) - tf(t)\), it follows that
    \begin{align*} 
        \frac{d}{dx} G(x) &= \frac{d}{dx} [ \int_0^x (x - t)f(t) ~dt ] \\
                          &= \frac{d}{dx} [ x \int_0^x f(t) ~dt - \int_0^x tf(t) ~dt ] \\
                          &= \frac{d}{dx} [x F(x)] - \frac{d}{dx}[ \int_0^x tf(t) ~dt ] .\\
    \end{align*}

    Applying the product rule to the first term and the 2nd FTC to the continuous 
    function \(t f(t)\), we get
    \begin{align*}
        G'(x) &= xF'(x) + F(x) - x f(x) \\
              &= xf(x)  + F(x) - x f(x) \\
              &= F(x) .\\
    \end{align*}
    Consequently, \(G''(x) = F'(x) = f(x)\).


\end{solution}


\begin{exercise}[12]
  Suppose that \(f,g:[a,b]\to\mb R\) are continuous and that \(\alpha,\beta\)
  are real numbers. Define
  \[
    H(x)
      =
    \int_a^x[\alpha f+\beta g]-\alpha\int_a^x[f]-\beta\int_a^x[g]
    \text{~~for all~} x\in[a,b]
  .\]
  Prove that \(H(a)=0\) and \(H'(x)=0\) for all \(x\in(a,b)\).
  Use this fact and the Identity Criterion to give an alternate proof of
  Theorem 6.15 for continuous functions.
\end{exercise}

\begin{solution}
    First, we note that since \(f\) and \(g\) are continuous on \([a,b]\), so is
    \(\alpha f + \beta g\). Then, since continuity implies integrability,
    \(f\), \(g\), and \(\alpha f + \beta g\) are integrable. Next, for any 
    integrable function \(h\) on \([a,b]\), \(\int_a^a h = 0\). Consequently, 
    we have
    \[ H(a) = \int_a^a [\alpha f + \beta g] - \alpha \int_a^a [f] - \beta \int_a^a [g] 
            = 0 - \alpha 0 - \beta 0 = 0 ,\]
    
    and we apply the 2nd FTC to obtain
    \begin{align*}
        H'(x) &= \frac{d}{dx} \Bigg[ \int_a^x \alpha f + \beta g \Bigg] - \alpha \frac{d}{dx} \Bigg[ \int_a^x [f] \Bigg] - \beta \frac{d}{dx} \Bigg[ \int_a^x [g] \Bigg] \\
              &= (\alpha f + \beta g)(x) - \alpha f(x) - \beta f(x) \\
              &= \alpha f(x) + \beta g(x) - \alpha f(x) - \beta f(x) \\
              &= 0 \\
    \end{align*}

    Now, because \(H(a) = 0\), we have that
    \[ \int_a^a [\alpha f + \beta g] = \alpha \int_a^a [f] + \beta \int_a^a [g] ,\]
    and because \(H'(x)\) is identically zero, we have that
    \[ \frac{d}{dx} \Bigg[ \int_a^x \alpha f + \beta g \Bigg] = \frac{d}{dx} \Bigg[ \alpha \int_a^x [f] + \beta \int_a^x [g] \Bigg] .\]
    Therefore, by the Identity Criterion, 
    \[ \int_a^x \alpha f + \beta g = \alpha \int_a^x f + \beta \int_a^x g \]
    which proves the linearity property of integrals for continous functions.
\end{solution}



\setcounter{chapter}{9}
\chapter{The Euclidean Space \texorpdfstring{$\mb R^n$}{Rn}}


\section{The Linear Structure of \texorpdfstring{$\mb R^n$}{Rn}
and the Scalar Product}

\begin{proposition}[10.2]
  Let \(\vect u,\vect v,\vect w\in\mb R^n\)
  and \(\alpha,\beta\in\mb R\). Then both of the following hold:
  \[
    \<\vect u,\vect v\>=\<\vect v,\vect u\>
  \]
  \[
    \<\alpha\vect u+\beta\vect w, \vect v\>
      =
    \alpha\<\vect u,\vect v\>+\beta\<\vect w,\vect v\>
  \]
\end{proposition}

\begin{proof}
    Since \(\mb R\) is commutative, \(u_i v_i = v_i u_i\) for numbers
    \(u_i, v_i\). It then follows that
    \[ \<\vect u, \vect v \> = \sumi u_i v_i = \sumi v_i u_i = \<\vect v, \vect u \> .\]

    Next,
    \begin{align*} 
        \< \alpha \vect u + \beta \vect w, \vect v \> &= \sumi (\alpha u_i + \beta w_i ) v_i \\
                    &= \sumi (\alpha u_i v_i + \beta w_i v_i ) \\
                    &= \sumi (\alpha u_i v_i) + \sumi (\beta w_i v_i) \\
                    &= \alpha \sumi u_i v_i + \beta \sumi w_i v_i \\
                    &= \alpha \< \vect u, \vect v \> + \beta \< \vect w, \vect v \> \\
    \end{align*}
\end{proof}

\begin{lemma}[10.4]
  For \(\vect u,\vect v\in\mb R^n\), \(\vect u,\vect v\) are
  orthogonal if and only if
  \(\|\vect u+\vect v\|^2 =\|\vect u\|^2+\|\vect v\|^2\).
\end{lemma}

\begin{proof}
    Here, we use the definition of the norm and apply Proposition 10.2
    (taking \(\alpha = \beta = 1\)):

    \begin{align*}
         \|\vect u + \vect v \|^2 &= \< \vect u + \vect v , \vect u + \vect v \> \\
                    &= \<\vect u, \vect u + \vect v \> + \<\vect v, \vect u + \vect v \> \\
                    &= \<\vect u + \vect v, \vect u \> + \<\vect u + \vect v, \vect v \> \\
                    &= \<\vect u, \vect u \> + \<\vect v, \vect u\> + \<\vect u, \vect v\> + \<\vect v, \vect v\> \\
                    &= \| \vect u \|^2 + 2 \< \vect u, \vect v \> + \| \vect v \|^2 \\
    \end{align*}

    Since norms are nonzero, the above shows that 
    \(\|\vect u + \vect v\|^2 = \|\vect u\|^2 + \|\vect v\|^2 \)
    iff \(\< \vect u, \vect v\> = 0\), or equivalently, iff \(\vect u\) and 
    \(\vect v\) are orthogonal.
\end{proof}



\begin{lemma}[10.5]
  For \(\vect u,\vect v\in\mb R^n\) where \(\vect v\not=\vect 0\),
  define \(\lambda=\frac{\<\vect u,\vect v\>}{\<\vect v,\vect v\>}\)
  and \(\vect w=\vect u-\lambda\vect v\). Then \(\vect v,\vect w\)
  are orthogonal and \(\vect u=\vect w+\lambda\vect v\).
\end{lemma}

\begin{proof}
    Clearly, 
    \[ \vect w + \lambda \vect v = (\vect u - \lambda \vect v) + \lambda \vect v = \vect u .\]
    
    To show orthogonality,
    \begin{align*} 
        \< \vect w, \vect v \> &= \< \vect u - \lambda \vect v , \vect v \> \\
                    &= \< \vect u, \vect v\> - \lambda \<\vect v, \vect v \> \\
                    &= \< \vect u, \vect v\> - \frac{\<\vect u, \vect v\>}{\<\vect v, \vect v\>} \< \vect v, \vect v \> \\
                    &= \< \vect u, \vect v\> - \< \vect u, \vect v \> \\
                    &= 0
    \end{align*}

\end{proof}

\begin{theorem}[10.6, The Cauchy-Schwarz Inequality]
  For any two vectors \(\vect u,\vect v\in\mb R^n\),
  \[
    |\<\vect u,\vect v\>|
      \leq
    \|\vect u\|\|\vect v\|
  .\]
\end{theorem}

\begin{proof}
    If \(\vect v = \vect 0\), then 
    \[ \< \vect u, \vect v \>  = \< \vect u, \vect 0\> = \sumi u_i 0 = 0 \]
    and \(\|\vect v\| = \<\vect v, \vect v\> = 0 \). It follows that
    \[ 0 = | \< \vect u, \vect v \> | \leq \|\vect u\| \cdot \|\vect v \| = 0 .\]
    Now consider when \(\vect v \neq \vect 0\). Define 
    \(\lambda = \<\vect u, \vect v\> / \< \vect v, \vect v\>\) like in the previous
    lemma. Then \(\vect u - \lambda \vect v\) is orthogonal to \(\vect v\) (and
    consequently \(\lambda \vect v\)). Then,
    \begin{align*} 
        0 &\leq \<\vect u - \lambda \vect v, \vect u - \lambda \vect v \> \\
          &= \|\vect u\|^2 + \|\lambda \vect v\|^2 - 2\<\vect u, \vect \lambda \vect v \> \\
          &= \|\vect u\|^2 + \lambda^2 \|\vect v\|^2 - 2 \lambda \<\vect u, \vect v \> \\ 
          &= \|\vect u\|^2 + \frac{\<\vect u, \vect v\>^2}{\<\vect v, \vect v\>^2} \<\vect v, \vect v\> - 2\lambda \<\vect u, \vect v\> \\
          &= \|\vect u\|^2 + \frac{\<\vect u, \vect v\>^2}{\<\vect v, \vect v\>} - 2 \frac{\<\vect u, \vect v\>^2}{\<\vect v, \vect v\>} \\
          &= \|\vect u\|^2 - \frac{\<\vect u, \vect v\>^2}{\|\vect v\|^2}. \\
    \end{align*}

    Therefore, we have \(\<\vect u, \vect v\>^2 \leq \|\vect u\|^2 \|\vect v\|^2 \), which
    after taking the square root to both sides gives our result.
\end{proof}

\begin{theorem}[10.7, The Triangle Inequality]
  For any two vectors \(\vect u,\vect v\in\mb R^n\),
  \[
    \|\vect u+\vect v\|
      \leq
    \|\vect u\|+\|\vect v\|
  .\]
\end{theorem}

\begin{proof}
    Clearly, the inequality holds iff 
    \[ \|\vect u + \vect v\|^2 \leq (\|\vect u \| + \|\vect v\|)^2 .\]

    From earlier computation, we know
    \[ \|\vect u + \vect v\|^2 = \|\vect u\|^2 + 2\<\vect u, \vect v\> + \|\vect v\|^2 .\]

    Then, by the Cauchy-Schwarz inequality,
    \[ \|\vect u + \vect v\|^2 \leq 
        \|\vect u\|^2 + 2\|\vect u\|\|\vect v\| + \|\vect v \|^2 
        = (\|\vect u\| + \|\vect v\|)^2 \]
\end{proof}

\begin{exercise}[3]
  Show that for \(\vect u\in\mb R^n\), \(\alpha\in\mb R\):
  \begin{enumerate}[(a)]
    \item \(\|\vect u\|=0\) if and only if \(\vect u=\vect 0\).
    \item \(\|\alpha\vect u\|=|\alpha|\|\vect u\|\).
  \end{enumerate}
\end{exercise}

\begin{solution}
    (a) Suppose \(\vect u = \vect 0\), then for any \(\vect v \in \mb R^n\),
    \[ \<\vect v, \vect 0\> = \sumi v_i 0 = \sumi 0 = 0 .\]
    It follows that 
    \[ \|\vect u\| = \sqrt{\<\vect u, \vect u \>} = \sqrt{\<\vect 0, \vect 0\>} = \sqrt{0} = 0 .\]

    Conversely, suppose \(\|\vect u\| = 0\). Then \(\<\vect u, \vect u\> = \sumi u_i^2 = 0 \)
    but since square terms are nonnegative, the sum can be zero iff \(u_i = 0\) for each
    \(i \in [n]\). Consequently, \(\vect u = \vect 0\).

    (b) We show that \( \|\alpha \vect u\|^2 = \alpha^2 \|\vect u\|^2\) from which the result
    follows.
    \[ \|\alpha \vect u\|^2 = \< \alpha \vect u, \alpha \vect u\> 
        = \alpha \<\vect u, \alpha \vect u\> 
        = \alpha \< \alpha \vect u, \vect u \>
        = \alpha^2 \< \vect u, \vect u \>
    = \alpha^2 \|\vect u\|^2 \]
\end{solution}

\begin{exercise}[4]
  For \(\vect u,\vect v\in\mathbb R^n\) verify the identity
  \[
    \|\vect u-\vect v\|^2
      =
    \|\vect u\|^2+\|\vect v\|^2-2\<\vect u,\vect v\>
  .\]
\end{exercise}

\begin{solution}
    \begin{align*}
        \|\vect u - \vect v \|^2 &= \<\vect u - \vect v, \vect u - \vect v\> \\
                    &= \<\vect u + (-\vect v), \vect u + (-\vect v)\> \\
                    &= \<\vect u, \vect u + (-\vect v)\> + \<-\vect v, \vect u + (-\vect v)\> \\
                    &= \<\vect u + (-\vect v), \vect u\> - \< \vect v, \vect u + (-\vect v) \> \\
                    &= \<\vect u, \vect u\> + \< -\vect v, \vect u\> - \<\vect u + (-\vect v), \vect v \> \\
                    &= \|\vect u\|^2 - \<\vect v, \vect u\> - \<\vect u, \vect v\> - \<-\vect v, \vect v \>\\
                    &= \|\vect u\|^2 - 2\<\vect u, \vect v\> + \|\vect v\|^2 \\
    \end{align*}
\end{solution}

\begin{exercise}[9]
  Let \(\vect u\in\mb R^n\) and suppose \(\|\vect u\|<1\).
  Show that for \(\vect v\in\mb R^n\),
  \(\|\vect v-\vect u\|<1-\|\vect u\|\) implies
  \(\|\vect v\|<1\).
\end{exercise}

\begin{solution}
    By the Triangle Inequality,
    \[ \|\vect v\| = \|(\vect v - \vect u) + \vect u \| 
        \leq \|\vect v - \vect u\| + \|\vect u\|
        < (1 - \|\vect u\| ) + \|\vect u\|
    = 1 .\]
\end{solution}

\begin{exercise}[10]
  Let \(\vect u\in\mb R^n\) and \(r>0\). Suppose \(\vect v,\vect w\in\mb R^n\)
  are at a distance less than \(r\) from \(\vect u\). Prove that if
  \(0\leq t\leq 1\), then the point \(t\vect v+(1-t)\vect w\) is also
  at a distance less than \(r\) from \(\vect u\).
\end{exercise}

\begin{solution}
    \begin{align*} 
        \| [t\vect v + (1-t)\vect w] - \vect u \| &= \| t\vect v + (1-t)\vect w - t\vect u - (1-t) \vect u \| \\ 
                        &= \| t[\vect v - \vect u] + (1-t)[\vect w - \vect u] \| \\
                        &\leq \| t(\vect v - \vect u )\| + \|(1 - t)(\vect w - \vect u) \| \\
                        &= t \|\vect v - \vect u \| + (1 - t) \| \vect w - \vect u \| \\
                        &< tr + (1-t)r \\
                        &= r
    \end{align*}
\end{solution}


\section{Convergence of Sequences in \texorpdfstring{$\mb R^n$}{Rn}}

\begin{theorem}[10.9, The Componentwise Convergence Criterion]
  Let \(\{\vect u_k\}\) be a sequence in \(\mb R^n\). Then
  \(\{\vect u_k\}\) converges to \(\vect u\) if and only if
  \(\{p_i(\vect u_k)\}\) converges to \(p_i(\vect u)\) for
  all \(1\leq i\leq n\).
\end{theorem}

\begin{proof}
    Suppose \(\vect u_k \to \vect u\). For any fixed \(i \in [n]\),
    \[ 0 \leq |p_i(\vect u_k) - p_i(\vect u)| = |p_i(\vect u_k - \vect u)|  \leq \|\vect u_k - \vect u \| \]
    for all \(k\). Taking the limit of \(k\), we get
    \[ 0 \leq \lim_{k \to \infty} |p_i(\vect u_k) - p_i(\vect u)| \leq \lim_{k \to \infty} \|\vect u_k - \vect u\| = 0 .\]
    Hence, \(p_i(\vect u_k) \to p_i(\vect u)\) for all \(i \in [n]\).


    Now suppose the converse. Then \(p_i(\vect u_k - \vect u) \to 0\) for \(i \in [n]\)
    and so
    \[ \lim_{k \to \infty} \|\vect u_k - \vect u \|^2 
        = \lim_{k \to \infty} \sumi [p_i(\vect u_k - \vect u)]^2 
        = \sumi \lim_{k \to \infty} [p_i(\vect u_k - \vect u)]^2 
        = \sumi 0 = 0 . \]

    Then, since the square root function is continous, we get 
    \[ \lim_{k \to \infty} \|\vect u_k - \vect u \| = 0 .\]
    Therefore, \(\vect u_k \to \vect u\).
\end{proof}

\begin{theorem}[10.10]
  Let \(\{\vect u_k\}\), \(\{\vect v_k\}\) be sequences in \(\mb R^n\)
  such that \(\{\vect u_k\}\) converges to \(\vect u\) and
  \(\{\vect v_k\}\) converges to \(\vect v\). Then for any
  \(\alpha,\beta\in\mb R\),
  \[
    \lim_{k\to\infty}[\alpha\vect u_k+\beta\vect v_k]
      =
    \alpha\vect u+\beta\vect v
  .\]
\end{theorem}

\begin{proof}
    By the previous theorem, it suffices to show that 
    \( p_{i}(\alpha \vect u_k + \beta \vect v_k) \to p_i(\alpha \vect u + \beta \vect v) \)
    for all \(i \in [n]\). Note that
    \[ p_i(\alpha \vect u_k + \beta \vect v_k) = \alpha p_i(\vect u_k) + \beta p_i(\vect v_k) .\]
    Since \(\vect u_k \to \vect u\), \(p_i(\vect u_k) \to p_i(\vect u)\).
    Likewise, \(p_i(\vect v_k) \to p_i(\vect v)\). Hence,
    \[  p_i(\alpha \vect u_k + \beta \vect v_k) = 
        \alpha p_i(\vect u_k) + \beta p_i(\vect v_k) 
        \to \alpha p_i(\vect u) + \beta p_i(\vect v) 
    = p_i(\alpha \vect u + \beta \vect v) .\]

\end{proof}

\begin{exercise}[1]
  Let \(\{\vect u_k\}\) be a sequence in \(\mb R^n\) that converges to
  \(\vect u\). Prove the following for all \(\vect v\in\mb R^n\):
  \[
    \lim_{k\to\infty}\<\vect u_k,\vect v\>=\<\vect u,\vect v\>
  .\]
\end{exercise}

\begin{solution}
    Since \(\vect u_k \to \vect u\), \(p_i(\vect u_k) \to p_i(\vect u)\) for
    \(i \in [n]\). Then,
    \begin{align*} 
        \lim_{k \to \infty} \<\vect u_k, \vect v \> &= \lim_{k \to \infty} \sumi p_i(\vect u_k) v_i \\
                        &= \sumi [\lim_{k \to \infty} p_i(\vect u_k)] v_i \\
                        &= \sumi p_i(\vect u) v_i \\
                        &= \<\vect u, \vect v \> \\
    \end{align*}
\end{solution}

\begin{exercise}[2]
  Let \(\{\vect u_k\}\) be a sequence in \(\mb R^n\) and
  \(\vect u\in\mb R^n\). Prove that if
  \[
    \lim_{k\to\infty}\<\vect u_k,\vect v\>=\<\vect u,\vect v\>
  \]
  holds for all \(\vect v\in\mb R^n\), then \(\{\vect u_k\}\) converges
  to \(\vect u\).
\end{exercise}

\begin{solution}
    Let \(\vect e_i\) be the ith standard coordinate vector in \(\mb R^n\).
    Since \(p_i(\vect u_k) = \<\vect u_k, \vect e_i \>\), by assumption, we have for \(i \in [n]\)
    \[ \lim_{k \to \infty} p_i(\vect u_k) = 
        \lim_{k \to \infty} \<\vect u_k, \vect e_i\> = 
    \< \vect u, \vect e_i \> .\]

    From this follows
    \begin{align*} 
        \lim_{k \to \infty} \vect u_k &= \lim_{k \to \infty} \sumi p_i(\vect u_k) \vect e_i \\
                    &= \lim_{k \to \infty} \sumi \<\vect u_k, \vect e_i \> \vect e_i \\
                    &= \sumi [\lim_{k \to \infty} \<\vect u_k, \vect e_i \>] \vect e_i \\
                    &= \sumi \<\vect u, \vect e_i \> \vect e_i \\
                    &= \sumi p_i(\vect u) \vect e_i \\
                    &= \vect u \\
    \end{align*}
\end{solution}

\begin{exercise}[5]
  Let \(\{\vect u_k\}\) be a sequence in \(\mb R^n\) that converges to
  \(\vect u\) where \(\|\vect u\|= r >0\). Prove that there is an index \(K\)
  where
  \[
    \|\vect u_k\|>\frac{r}{2}
    \text{~~if~}
    k\geq K
  .\]
\end{exercise}

\begin{solution}
    We first claim that \(\vect u_k \to \vect u\) implies 
    \(\|\vect u_k \| \to \|\vect u\|\). For this, it suffices to show that
    \( \|\vect u_k \|^2 \to \|\vect u \|^2\). And so
    \begin{align*}
        \lim_{k \to \infty} \|\vect u_k\|^2 &= \lim_{k \to \infty} \<\vect u_k, \vect u_k \> \\
                                            &= \lim_{k \to \infty} \sumi p_i(\vect u_k)^2 \\
                                            &= \sumi \lim_{k \to \infty} p_i(\vect u_k)^2 \\
                                            &= \sumi p_i(\vect u)^2 \\
                                            &= \< \vect u, \vect u \> \\
                                            &= \|\vect u\|^2 \\
    \end{align*}

    Choose \(\epsilon > 0\) to be less than \(r\). By convergence, there exists 
    a natural number \(K\) such that
    \[ | \|\vect u_k\| - \|\vect u\| | < \epsilon/2 \] 
    for \(k \geq K\), or equivalently, 
    \[ \|\vect u\| - \epsilon/2 < \|\vect u_k\| < \|\vect u\| + \epsilon/2 .\]
    This implies
    \[ 2 \|\vect u_k\| > 2\|\vect u\| - \epsilon = 2r - \epsilon > 2r - r = r \]
    so that
    \[ \|\vect u_k\| > \frac{r}{2} \text{~~if~~} k \geq K .\]
\end{solution}


\section{Open Sets and Closed Sets in \texorpdfstring{$\mb R^n$}{Rn}}

\begin{remark}
    Whenever possible, I opt for a direct proof for open and
    closed sets rather than rely on DeMorgan's laws and set-theoretic
    identities. Why? I prefer the challenge!
\end{remark}

\begin{example}[10.11]
  Let \(a<b\) be in \(\mb R\). Then \(\interior(a,b]=(a,b)\).
\end{example}

\begin{proof}
    By definition, \(\interior(a,b] \subseteq (a,b]\). Hence,
    it suffices to show that \((a,b) \subset \interior(a,b]\) but that
    \(b\) is not an interior point.

    Let \(u\) be a point in \((a,b)\). Define 
    \(R = \text{min~}(u-a, b-u)\) and pick \(r < 0\) so that \(r < R\).
    Now consider some \(v \in B_r(u)\). This means that 
    \(u - r < v < u + r\). If \(R = u -a\), then \(u - a \leq b - u\)
    so that \(2u \leq a + b \). From this we get
    \[ a = u - (u - a) < u - r < v < u + r < u + (u - a) \leq u + (b - u) = b \]
    and consequently, \(v \in (a, b)\). Else, if \(R = u - b\), 
    then \(b - u \leq u - a\) and \(a + b \leq 2u\). Consequently,
    \[ a = (a + b) - b  \leq 2u - b = u - (b - u) < u - r < v < u + r < u + (b - u) = b \]
    which means \(v \in (a, b)\).
    Altogether, this shows that \((a, b) \subset \interior(a,b]\). Last,
    we consider point \(b\). For any \(r > 0\), \(B_r(b)\) is not a subset
    of \((a,b]\) since we can pick a point \(z\) such that \(b < z < b + r\).
    Therefore, \(b\) is not an interior point of \((a,b]\) and so
    \(\interior(a,b] = (a,b)\).
\end{proof}

\begin{example}[10.12]
  Let \(\mb Q\subseteq\mb R\) be the set of rational real numbers.
  Then \(\interior\mb Q=\emptyset\).
\end{example}

\begin{proof}
    Trivially, \(\emptyset \subset \interior \mb Q\), so it 
    suffices to show that no point in \(\mb Q\) is interior.

    Let \(q\) be any rational number, and choose any \(r > 0\)
    for an open ball \(B_r(q)\) in \(\mb R\). Because the irrational
    numbers are dense in \(\mb R\) and \(B_r(q) = (q - r, q + r)\)
    (an open interval), there exists an irrational number \(s\)
    in \(B_r(q)\). Consequently, \(B_r(q) \not\subset \mb Q\).
    Hence \(q\) is not an interior point and \(\interior \mb Q = \emptyset\).
\end{proof}

\begin{proposition}[10.13]
  Every open ball \(B_r(\vect u)\) in \(\mb R^n\) is open.
\end{proposition}

\begin{proof}
    Let \(\vect v \in B_r(\vect u)\). Then, by definition
    \(dist(\vect u , \vect v) < r\) and so we define 
    \(R = r - dist(\vect u, \vect v) > 0 \). Now consider
    any \(w \in B_{R}(\vect v)\). Then by the Triangle
    Inequality
    \[ dist(\vect w, \vect u) \leq dist(\vect w, \vect v) + dist(\vect v, \vect u)
        < R + dist(\vect v, \vect u) 
        = [r - dist(\vect u, \vect v)] + dist(\vect u, \vect v) 
    = r \]
    which shows that \(B_{R}(\vect v) \subseteq B_{r}(\vect u)\).

    Hence, every point in \(B_r(\vect u)\) is interior, and so
    \(B_r(\vect u)\) is open.
\end{proof}

\begin{example}[10.14]
  Let \(a<b\) be in \(\mb R\). Then \([a,b]\) is closed.
\end{example}

\begin{proof}
    This follows from Theorem 2.22 and by definition of 
    a closed set. As a brief summary, we show that for 
    \(c_n \to c \) in \([a,b]\), we must have
    \(\limit [b - c_n] = b - c\) and \(\limit [c_n - a] = c - a\).
    Then since \(b - c \geq 0 \) and \(c - a \geq 0\), we
    have by transitivity thant \(b \geq c \geq a \) and so
    \(c \in [a,b]\).
\end{proof}

\begin{example}[10.15]
  The set
  \[
    [-1,1]\times[-1,1]
      =
    \{(x,y)\in\mb R^2:-1\leq x\leq 1 \text{~and~} -1\leq y\leq 1\}
  \]
  is closed in \(\mb R^2\).
\end{example}

\begin{proof}
    Let \(\{(x_n, y_n)\}\) be a sequence in \([-1,1]\times[-1,1]\) that
    converges to \((x,y)\). By the Componentwise Convergence Criterion,
    we must have that \(x_n \to x\) and \(y_n \to y\). Now since 
    \(\{x_n\}, \{y_n\}\) are sequences in \([-1, 1]\) and \([-1,1]\)
    is closed in \(\mb R\) (by the previous example), it follows that \(x, y \in [-1,1]\).
    Consequently, \((x,y) \in [-1,1] \times [-1,1]\) and so this
    set is closed in \(\mb R^2\).
\end{proof}

\begin{theorem}[10.16, The Complementing Characterization]
  A subset \(A\subseteq\mb R^n\) is open if and only if its complement
  \(\mb R^n\setminus A\) is closed.
\end{theorem}

\begin{proof}
    From now on, we use the notation \(A^c\) for \(\mb R^n \setminus A\).
    Suppose \(A\) is open, and let \(\{\vect x_n\}\) be a sequence in
    \(A^c\) that converges to point \(\vect x\). Suppose on the contrary
    that \(\vect x \not\in A^c\). Then \(\vect x \in A\). Because \(A\)
    is open, there exists an open ball \(B_r(\vect x) \subset A\). However
    this means that no point in the sequence \(\{\vect x_n\}\) lies in
    \(B_r(\vect x)\); this contradicts our assumption that 
    \(\vect x_n \to \vect x\). Hence \(\vect x \in A^c\) and so \(A^c\)
    is closed.

    Conversely, suppose \(A^c\) is closed, and let \(\vect y \in A\).
    Suppose on the contrary that \(\vect y\) is not an interior point 
    of \(A\). Then, every open ball around \(\vect y\) intersects
    \(A^c\) at a point distinct from \(\vect y\). From this, we can 
    construct the following sequence: for each natural number \(k\),
    pick a point \(\vect y_k\) from \(B_{\frac{1}{k}}(\vect y) \cap A^c\).
    Then, because \(\frac{1}{k} \to 0\) as \(k \to \infty\), we
    have that \(\vect y_k \to \vect y\). However, this means that
    \(\vect y_k\) is a convergent sequence in \(A^c\). By assumption,
    \(A^c\) is closed and so \(\vect y \in A^c\); this is a contradiction.
    Hence, \(\vect y\) is an interior point of \(A\). Thus, \(A\)
    is open.

\end{proof}

\begin{proposition}[10.17.i]
  The union of a collection of open subsets of \(\mb R^n\) is open.
\end{proposition}

\begin{proof}
    Let \(U = \bigcup_{\alpha \in I} U_\alpha\) where \(\{U_\alpha\}\) is a collection
    of open subsets of \(\mb R^n\). We show that every point \(\vect x\)
    in \(U\) is interior. Since \(\vect x \in U\), \(\vect x \in U_\alpha\)
    for some \(\alpha\). Because \(U_\alpha\) is open, there exists \(r > 0\)
    such that \(B_r(\vect x) \subset U_\alpha\). Then because
    \(U_\alpha \subset U\), we have that \(B_r(\vect x) \subset U\).
    Hence, \(U\) is open.
\end{proof}

\begin{proposition}[10.17.ii]
  The intersection of a collection of closed subsets of \(\mb R^n\) is closed.
\end{proposition}

\begin{proof}
    Let \(C = \bigcap_{\alpha \in I} C_\alpha\) where \(\{C_\alpha\}\) is
    a collection of closed subsets of \(\mb R^n\). Let \(\{\vect x_n\}\)
    be a sequence in \(C\) that converges to \(\vect x\). By definition,
    this sequence \(\{\vect x_n\}\) is in every \(C_\alpha\). Since 
    each of these sets is closed, we have that \(\vect x \in C_\alpha\)
    for all \(\alpha\). Hence \(\vect x \in C\). Thus \(C\) is closed.
\end{proof}

\begin{proposition}[10.18.i]
  The intersection of a finite collection of
  open subsets of \(\mb R^n\) is open.
\end{proposition}

\begin{proof}
    Let \(U = U_1 \cap U_2 \cap ... \cap U_n\) be the intersection
    of finitely many open subsets \(U_i\) of \(\mb R^n\).
    Let \(\vect x \in U\). Then \(\vect x \in U_i\) for all \(i \in [n]\).
    Since each of these \(U_i\) is open, there exists \(r_i > 0\)
    where \(B_{r_i}(\vect x) \subset U_i\). Define 
    \(r = \text{min~}\{r_1, r_2, ..., r_n\}\). It immediately
    follows that \(B_{r}(\vect u) \subset B_{r_i}(\vect u) \subset U_i\)
    for \(i \in [n]\). Thus, \(B_{r}(\vect u) \in U\) and so \(U\)
    is open.
\end{proof}

\begin{proposition}[10.18.ii]
  The union of a finite collection of
  closed subsets of \(\mb R^n\) is closed.
\end{proposition}

\begin{proof}
    Let \(C = C_1 \cup C_2 \cup ... \cup C_n \) be the union
    of finitely many closed subsets \(C_i\) in \(\mb R^n\).
    Then let \(\{\vect x_n\}\) be a sequence in \(C\) that
    converges to \(\vect x\). By definition, \(\vect x_n \in C_i\)
    for some \(i\) for every \(n\). Since \(n\) is finite, it
    follows that there exists some particular \(j \in [n]\) for which
    \(\{\vect x_n\} \cap C_j \) is nonempty and countable (not finite). 
    To put it another way, the mapping \(k \mapsto nk\) is an injection
    on the natural numbers and so by the Pigeonhole Principle, at
    least one intersection must contain a countable number of elements.
    Anyway, this intersection is a subsequence \(\{\vect x_{n_j}\}\) of 
    \(\{\vect x_n\}\). Then clearly \(\vect x_{n_j} \to \vect x\). 
    Because \(C_j\) is closed, \(\vect x \in C_j\) and so \(\vect x \in C\).
\end{proof}

\begin{proposition}[10.19.i]
  \(A\subseteq\mb R^n\) is open if and only if \(A\cap\boundary A=\emptyset\).
\end{proposition}

\begin{proof}
    Suppose \(A\) is open, and let \(\vect x \in A \cap \boundary A\). 
    Because \(\vect x \in A\), there exists \(r > 0\) such that 
    \(B_{r}(\vect x) \subset A\). However, this implies that 
    \(B_{r}(\vect x) \cap \boundary A = \emptyset\) because
    \(B_{r}(\vect x)\) does not intersect \(A^c\). Consequently,
    \(\vect x \not\in \boundary A\), a contradiction. Therefore,
    \(A \cap \boundary A = \emptyset \).

    Conversely, suppose \(A \cap \boundary A = \emptyset\) and
    let \(\vect x \in A\). By assumption, \(\vect x \not\in \boundary A\)
    and so, by definition, there exists an open ball \(B_r(\vect x)\)
    that does not intersection \(A^c\). Hence \(B_r(\vect x) \subset A\)
    and so \(A\) is open.
\end{proof}

\begin{proposition}[10.19.ii]
  \(A\subseteq\mb R^n\) is closed if and only if \(\boundary A\subseteq A\).
\end{proposition}

\begin{proof}
    Suppose \(A\) is closed. Let \(\vect x \in \boundary A\). Then
    every open ball around \(\vect x\) intersects \(A\). In particular,
    we form a sequence of points \(\vect x_k \) in \(A\) taken from
    \(B_{1/k}(\vect x)\). Then \(\vect x_k \to \vect x\). Since \(A\)
    is closed, we have that \(\vect x \in A\). Thus, \(\boundary A \subseteq A\).

    Now suppose the converse. We show that \(A^c\) is open. Let \(\vect x \in A^c\).
    Then \(\vect x \not\in \boundary A \), which means there exists an open
    ball \(B_r(\vect x)\) contained in \(A^c\). Hence \(A^c\) is open. By 
    Theorem 10.16, this means its complement is closed, which is \(A\).
\end{proof}

\begin{exercise}[2]
  Determine which of the following subsets of \(\mb R^2\) are open, closed,
  neither, or both.
  \begin{enumerate}[(a)]
    \item \(\{(x,y):x^2>y\}\)
    \item \(\{(x,y):x^2+y^2=1\}\)
    \item \(\{(x,y):x \text{~is rational}\}\)
    \item \(\{(x,y):x\geq 0,~y\geq0\}\)
  \end{enumerate}
\end{exercise}

\begin{solution}
  \begin{enumerate}[(a)]
    \item This set is open in \(\mb R^2\). To see why, let \((h, k)\) be a
          point from the set. We claim that there exists a point \((x_0, y_0)\)
          on the curve \(g(x) = x^2\) where the distance \(R\) from \(g(x)\) to 
          \((h,k)\) is smallest. It follows that if we pick any \(r > 0\) less
          than \(R\), then \(B_{r}((x_0, y_0))\) lies entirely in the set.
          Consider the function \[f(x) = (x - h)^2 + (x^2 - k)^2 .\] Taking the
          derivative and setting it to zero, we get
          \[ 0 = (x - h) + 2x(x^2 - k) = 2x^3 + x(1 - 2k) - h .\]
          This is an odd-degree polynomial, and thus must have at least one 
          real root. Moreover, a positive leading coefficient tells us
          that \(f'(x) \to \infty\) as \(x \to \infty\) and \(f'(x) \to -\infty\)
          as \(x \to -\infty\). This implies that a real root must be a 
          minimum (by the First Derivative test); call this root \((x_0, y_0)\).
          This proves our claim, and therefore every point in the set is 
          an interior point. Thus, our set is open.

          This set is not closed because it doesn't include \(g(x)\), which
          is its boundary.

    \item The unit circle \(S^1\) is closed in \(\mb R^2\): First, we note
          that \(B_{1}(\vect 0)\) is open by Proposition 10.13. Second, 
          we can either appeal to Exercise 3 (below) or re-adapt the argument
          from (a) to show that the set 
          \(O = \{\vect u \in \mb R^2 : \|\vect u\| > 1 \}\) is open. Then
          \(\mb R^2 \setminus S^1 = B_{1}(\vect 0) \cup O\) is the union of
          two open sets, which is open (by Proposition 10.17i). Therefore,
          \(S^1\) is closed by Theorem 10.16.

          Now, since \(\boundary S^1 = S^1\), \(S^1\) is not open
          (by Proposition 10.19i).

    \item This set is neither open or closed. To show that the
          set is not open, we note that this set is equivalent to
          \(\mb Q \times \mb R\) in \(\mb R^2\). By Example 10.12, 
          \(\interior \mb Q = \emptyset\), and since \(\mb R\) is 
          open, \(\interior \mb R = \mb R\). It follows that 
          \[\interior (\mb Q \times \mb R) = \emptyset \times \mb R .\]
          Thus, this set cannot be open since it is not equal to its 
          interior (a more direct approach would be to repeat the 
          argument of example 10.12 but with open circles). 

          To show that the set is not closed, construct the
          sequence \( \{ (1 + \frac{1}{n})^n, 0) \}\). Since \(n\)
          is a natural number, \(1 + \frac{1}{n}\) is rational 
          and hence \((1 + \frac{1}{n})^n\) is rational. The
          sequence converges to \((e, 0)\), but because \(e\)
          is an irrational number, this point is not inside
          the set. Hence, the set is not closed.

    \item The first quadrant \(Q_1\) is closed in \(\mb R^2\): Let 
          \(\{(x_n, y_n)\}\) be a sequence in \(Q_1\) that converges to
          the point \((x, y)\). By the Componentwise Criterion,
          \(x_n \to x\) and \(y_n \to y\) in \(\mb R\). Now, since
          \(x_n \geq 0\) for all indices \(n\), \(x \geq 0\) by Lemma
          2.21. Similarly, \(y \geq 0\). Hence, \((x, y) \in Q_1\)
          and so \(Q_1\) is closed.
        
          \(Q_1\) is not open since \( Q_1 \cap \boundary Q_1 \)
          is the union of the nonnegative \(x\) and \(y\) axes.
        
  \end{enumerate}
\end{solution}

\begin{exercise}[3]
  Let \(r>0\) and \(O=\{\vect u\in\mb R^n:\|\vect u\|>r\}\). Prove that \(O\)
  is open.
\end{exercise}

\begin{solution}
    Let \(v \in O\). Choose \(R = \|\vect u\| - r > 0\) and consider
    \(B_R(\vect u)\). Then for \(\vect v \in B_R(\vect u)\), we have
    \[ \|\vect u\| = \|(\vect u - \vect v) + \vect v\| 
                  \leq \|\vect u - \vect v\| + \|\vect v\|
              < R + \|\vect v\| = \|\vect u\| - r + \|\vect v\| .\]
    Adding \(r - \|\vect u\|\) to both sides then gives us
    \(r < \|\vect v\|\), as desired. Hence \(B_R(\vect u) \subset O\)
    and so \(O\) is open.
\end{solution}

\begin{exercise}[7a]
  Show that \(A\subseteq\mb R^n\) is open if and only if
  \[
    \vect w + A = \{\vect w+\vect u:\vect u\in A\}
  \]
  is open for all \(\vect w\in\mb R^n\).
\end{exercise}

\begin{solution}
    Suppose \(A\) is open. Fix some \(\vect w \in \mb R^n\),
    and let \(\vect y \in \vect w + A\). Then 
    \(\vect y = \vect w + \vect u\) for some \(\vect u \in A\). 
    Since \(A\) is open, there exists \(r > 0\) such that
    \(B_r(\vect u) \subset A\). We claim that 
    \(B_r(\vect y) \subset \vect w + A\). Indeed, if \(\vect z \in B_r(\vect y)\),
    then
    \[ r > \| \vect z - \vect y \| = \| \vect z - (\vect w + \vect u) \| 
    = \| (\vect z - \vect w) - \vect u \| \]
    which shows that \(\vect z - \vect w \in B_r(\vect u)\) and therefore
    is an element of \(A\). It follows that
    \[ \vect z = \vect w + (\vect z - \vect w) \in w + A \]
    and so \(B_r(\vect y) \subset \vect w + A\). Thus, \(\vect w + A\) is open.

    Now suppose the converse and take \(\vect w = 0\). Then
    \(\vect w + A = \vect 0 + A = A\) is open.
\end{solution}

\begin{exercise}[12]
  For \(A\subseteq\mb R^n\), denote its closure by
  \[
    \closure A = \interior A \cup \boundary A
  .\]
  Prove that \(A\subseteq \closure A\). Then prove that
  \(A=\closure A\) if and only if \(A\) is closed.
\end{exercise}

\begin{solution}
    Let \(\vect x \in A\). If \(\vect x \in \interior A\),
    then by definition \(\vect x \in \closure A\). Otherwise,
    every open ball around \(\vect x\) intersects \(A^c\)
    (by definition of not being in the interior of \(A\)). But
    since \(\vect x \in A\), every open ball around \(\vect x\)
    intersects both \(A\) and \(A^c\). Hence, \(\vect x \in \boundary A\).
    Therefore, \(A \subseteq \closure A\).

    By a previous proposition, we know that \(A\) is closed iff
    \(\boundary A \subseteq A\). The latter implies that
    \(\closure A = \interior A \cup \boundary A \subseteq A\). 
    And so, combining the previous step, \(A\) is closed iff
    \(\closure A = A \).
\end{solution}


\chapter{Continuity, Compactness, and Connectedness}


\section{Continuous Functions and Mappings}

\begin{proposition}[11.1]
  For each \(i\in\{1,\dots,n\}\), the \(i\)th projection map
  \(p_i:\mb R^n\to\mb R\) is continuous.
\end{proposition}

\begin{proof}
    Suppose \(\vect u_k \to \vect u\). By the Componentwise
    criterion, \(p_i(\vect u_k) \to p_i(\vect u)\) for an 
    arbitrary \(i \in [n]\). Since \(\vect u\) is an arbitrary
    point in \(\mb R^n\), we have that \(p_i\) is continuous.
\end{proof}

\begin{theorem}[11.3]
  Let \(\vect u\in A\subseteq \mb R^n\) and \(h,g:A\to\mb R\) be continuous
  at \(\vect u\). Then for \(\alpha,\beta\in\mb R\), the following functions
  are continuous at \(\vect u\):
  \[
    \alpha h+\beta g : A\to\mb R
      \hspace{4em}
    h\cdot g : A\to\mb R
  .\]
  Also if \(g(\vect v)\not=0\) for all \(\vect v\in A\), then the following
  function is also continuous at \(\vect u\):
  \[
    \frac{h}{g} : A\to\mb R
  .\]
\end{theorem}

\begin{proof}
    Suppose \(\vect u_k \to \vect u\). Then, by the linearity property of 
    sequences and the fact that \(g\) and \(h\) are continuous at \(\vect u\), 
    we have
    \[ \lim_{k \to \infty} (\alpha h + \beta g)(\vect u_k) = 
    \alpha \lim_{k \to \infty} h(\vect u_k) + \beta \lim_{k \to \infty} g(\vect u_k) = 
    \alpha h(\vect u) + \beta g(\vect u) = (\alpha h + \beta g)(\vect u) .\]
    Similarly,
    \[ \lim_{k \to \infty} (h \cdot g)(\vect u_k) = 
       \lim_{k \to \infty} [h(\vect u_k) g(\vect u_k)] = 
       [\lim_{k \to \infty} h(\vect u_k)][\lim_{k \to \infty} g(\vect u_k)] = 
       h(\vect u)g(\vect u) = (h \cdot g)(\vect u) \]
    and
    \[ \lim_{k \to \infty} \frac{h}{g}(\vect u_k) = 
       \lim_{k \to \infty} \frac{h(\vect u_k)}{g(\vect u_k)} = 
       \frac{ \lim_{k \to \infty} h(\vect u_k) }{ \lim_{k \to \infty} g(\vect u_k) } =
       \frac{h(\vect u)}{g(\vect u)} =
       \frac{h}{g}(\vect u) \]
    for \(g(\vect v) \neq 0\), \(\vect v \in A\).
\end{proof}

\begin{theorem}[11.5]
  Let \(\vect u\in A\subseteq \mb R^n\) and \(G: A\to\mb R^m\) be continuous
  at \(\vect u\). Also let \(G(A)\subseteq B\subseteq \mb R^m\) and
  \(H:B\to\mb R^k\) be continuous at \(G(\vect u)\). Then the composition
  \[
    H\circ G : A\to\mb R^k
  \]
  is continuous at \(\vect u\).
\end{theorem}

\begin{proof}
    Suppose \(\vect u_k \to \vect u\) in \(A\). By continuity, 
    \(G(\vect u_k) \to G(\vect u)\). Since \(G(A) \subseteq B\), this
    is a sequence in \(B\) and so by continuity 
    \( H(G(\vect u_k)) \to H(G(\vect u)) \). Thus, 
    \[\lim_{k \to \infty} (H \circ G)(\vect u_k) = H(G(\vect u)) = (H \circ G)(\vect u).\]
\end{proof}

\begin{theorem}[11.9, The Componentwise Continuity Criterion]
  Let \(\vect u\in A\subseteq \mb R^n\) and \(F:A\to\mb R^m\).
  Then \(F\) is continuous at \(\vect u\) if and only if
  \(F_i=p_i\circ F:A\to\mb R\) is continuous at \(\vect u\) for each
  \(i\in\{1,\dots,n\}\).
\end{theorem}

\begin{proof}
    By the Componentwise convergence criterion, the sequence \(\{F(\vect u_k)\}\)
    converges iff \(\{p_i(F(\vect u_k))\}\) converges for \(i \in [n]\). By 
    definition, \(p_i \circ F = F_i\). Hence, \(F\) is continuous at \(\vect u\)
    iff \(\vect u_k \to \vect u\) implies \(F(\vect u_k) \to F(\vect u)\), which
    occurs iff \(\vect u_k \to \vect u\) implies \(F_i(\vect u_k) \to F_i(\vect u)\)
    (that is, \(F_i\) is continuous for \(i \in [n]\)).
\end{proof}

\begin{theorem}[11.11, Exercise 12]
  Let \(\vect u\in A\subseteq \mb R^n\) and \(F:A\to\mb R^m\).
  Then \(F\) is continuous at \(\vect u\) if and only if for each
  \(\epsilon>0\) there exists \(\delta>0\) such that
  \(\|\vect v-\vect u\|<\delta\)
  implies \(\|F(\vect v)-F(\vect u)\|<\epsilon\).
\end{theorem}

\begin{proof}
    Suppose that \(F\) is continuous at \(\vect u\) but the epsilon-delta
    criterion does not hold. Then there exists \(\epsilon > 0\) where
    for all \(\delta > 0\) we have \(\|\vect v - \vect u\| < \delta\)
    but \(\|F(\vect v) - F(\vect u)\| \geq \epsilon\). Taking \(\delta = 1/n\) 
    for all natural numbers \(n\), we have a sequence \(\{\vect u_k\}\) 
    that converges to \(\vect u\). Hence, by continuity \(\{F(\vect u_k)\}\) 
    converges to \(F(\vect u)\), which contradicts the assumption that
    \(\|F(\vect u_k) - F(\vect u)\| \geq \epsilon\) for all \(n\).  

    Conversely, suppose the epsilon-delta criterion holds at \(\vect u\).
    Let \(\vect u_k \to \vect u\). By assumption, for any \(\epsilon > 0\),
    there exists \(\delta > 0\) such that \(\|\vect u_k - \vect u\| < \delta\)
    imples \(\|F(\vect u_k) - F(\vect u)\| < \epsilon\). Since \(\{\vect u_k\}\)
    is a convergent sequence, there exists index \(N\) where \(k \geq N\) implies
    \(\|\vect u_k - \vect u\| < \delta\). Hence, there exists \(N\) such
    that \(k \geq N\) imples \(\|F(\vect u_k) - F(\vect u)\| < \epsilon\).
    Therefore, we have \(F(\vect u_k) \to F(\vect u)\), which shows that
    \(F\) is continuous.
\end{proof}

\begin{theorem}[11.12]
  Let \(U\subseteq\mb R^n\) be open and \(F:U\to\mb R^m\).
  Then \(F\) is continuous
  if and only if \(F^{-1}(V)\) is an open subset of \(\mb R^n\) for every
  open \(V\subseteq\mb R^m\).
\end{theorem}

\begin{proof}
    Suppose \(F\) is continuous, and let \(V\) be an open set in \(\mb R^m\).
    To show that \(F^{-1}(V)\) is open, we prove that every point is 
    interior. Let \(\vect u \in F^{-1}(V)\). Then \(F(\vect u) \in V\),
    and since \(V\) is open, there exists \(\epsilon > 0\) such that
    \(B_{\epsilon}(F(\vect u)) \subset V\). By continuity, there exists
    a \(\delta > 0\) such that \(\|\vect v - \vect u\| < \delta\) implies
    \(\|F(\vect v) - F(\vect u)\| < \epsilon\). In other words,
    \(F(B_{\delta}(\vect u)) \subset B_{\epsilon}(F(\vect u)) \subset V\),
    and so by definition \(B_{\delta} \subset F^{-1}(V)\). Hence, the
    inverse image is open.

    Now suppose the converse. Let \(\epsilon > 0\). Then
    \(B_{\epsilon}(F(\vect u))\) is open in \(\mb R^m\), and so by assumption,
    \(F^{-1}(B_{\epsilon}(F(\vect u)))\) is open in \(U\). Since \(\vect u\)
    is an element of this set, it is an interior point. Consequently, 
    there exists \(\delta > 0\) such that \(B_{\delta}(\vect u)\) is 
    a subset. Moreover, this implies 
    \(F(B_{\delta}(\vect u)) \subset B_{\epsilon}(F(\vect u))\), which
    is equivalent to the epsilon-delta criterion. Therefore, \(F\)
    is continuous.
\end{proof}

\begin{example}[11.15]
  Use corollary 11.13 and proposition 10.18.i to prove that
  \(U=\{\vect u\in\mb R^n:a<\|\vect u\|<b\}\) is open.
  (You may assume \(f(\vect u)=\|\vect u\|\) is continuous.)
\end{example}

\begin{solution}
    We know that \(f\) is continuous since we can
    take \(\delta = \epsilon\) and by the reverse Triangle Inequality obtain
    \[ | \|\vect u\| - \|\vect v\| | \leq \|\vect u - \vect v\| < \delta = \epsilon .\]
    It then follows from Corollary 11.13 that the sets
    \(U_1 = \{\vect u \in \mb R^n : \|\vect u\| < b\}\) and
    \(U_2 = \{\vect u \in \mb R^n : \|\vect u\| > a\}\) are open.
    Noting that \(U = U_1 \cap U_2\), since the union of two
    open sets is open, \(U\) is open.
\end{solution}

\begin{exercise}[3]
  Fix a point \(\vect v\in\mb R^n\). Prove that \(f:\mb R^n\to\mb R\)
  defined by \(f(\vect u)=\<\vect u,\vect v\>\) is continuous.
\end{exercise}

\begin{solution}
    Suppose \(\vect u_k \to \vect u\). By exercise 1 in section 10.2,
    we have that 
    \(\lim_{k \to \infty} \<\vect u_k, \vect v\> = \<\vect u, \vect v\>\).
    Hence, by definition, \(f\) is continuous.
\end{solution}

\begin{exercise}[6]
  Suppose \(f,g:\mb R^n\to\mb R\) are continuous. Prove that
  \(\{\vect u\in\mb R^n:f(\vect u)=g(\vect u)=0\}\) is closed.
  (Hint: use corollary 11.13 and proposition 10.17.ii.)
\end{exercise}

\begin{solution}
    First, the sets \(C = \{\vect u \in \mb R^n : f(\vect u) = 0\}\)
    and \(D = \{\vect u \in \mb R^n: g(\vect u) = 0\}\) are closed:
    being the complement of the open sets
    \(\{\vect u \in \mb R^n : f(\vect u) < 0\} \cup 
      \{\vect u \in \mb R^n : f(\vect u) > 0\} \)
    and
    \(\{\vect u \in \mb R^n : g(\vect u) < 0\} \cup 
      \{\vect u \in \mb R^n : g(\vect u) > 0\} \), respectively.
    It follows that 
    \(\{\vect u \in \mb R^n : f(\vect u) = g(\vect u) = 0\} = C \cap D\)
    is closed, being the intersection of two closed sets.
\end{solution}

\begin{exercise}[11]
  Let \(A\subseteq\mb R^n\). The characteristic function
  \(\phi_A:\mb R^n\to\mb R\) for \(A\) is defined to be
  \[
    \phi_A(\vect u) =
    \begin{cases}
      1 & \text{if } \vect u\in A \\
      0 & \text{if } \vect u\not\in A
    \end{cases}
  .\]
  Prove that \(\phi_A\) is continuous at points in \(\interior A\)
  and \(\exterior A\), but not continuous at points in \(\boundary A\).
\end{exercise}

\begin{solution}
    Let \(\vect u \in \interior A\). Then by definition, there exists
    an \(\epsilon > 0\) such that \(B_{\epsilon}(\vect u) \subset A\).
    So consider \(\vect u_k \to \vect u\). Then, there exists natural
    number \(N\) such that \(k \geq N\) implies 
    \(\vect u_k \in B_{\epsilon}(\vect u)\). For these terms,
    \(\phi_A(\vect u_k) = 1\) and \(\phi_A(\vect u) = 1\). Thus,
    \(\lim_{k \to \infty} \phi_A(\vect u_k) = 1 = \phi_A(\vect u) \).
    Similarly, if \(\vect v \in \exterior A\) and \(\vect v_k \to \vect v\),
    we get \(\lim_{k \to \infty} \phi_A(\vect v_k) = 0 = \phi_A(\vect v)\).
    Last, consider \(\vect w \in \boundary A\). For each natural number \(k\),
    there exists points \(\vect y_k, \vect z_k \in B_{1/k}(\vect w)\)
    such that \(\vect y_k \in A\) and \(\vect z_k \not\in A\). It follows
    that \(\vect y_k \to \vect w\) and \(\vect z_k \to \vect w\), but
    \(\lim_{k \to \infty} \phi_A(\vect y_k) = 1\) while 
    \(\lim_{k \to \infty} \phi_A(\vect z_k) = 0\). If \(\vect w \not\in A\),
    then the former sequence does not converge to \(\phi_A(\vect w) = 0\), and
    if \(\vect w \in A\), then the latter sequence does not converge to
    \(\phi_A(\vect w) = 1\). Hence, \(\phi_A\) cannot be continuous at \(\vect w\).
    Since the points \(\vect u, \vect v\) and \(\vect w\) were arbitrary, this
    shows that \(\phi_A\) is continuous on \(\interior A\) and \(\exterior A\),
    but not on \(\boundary A\).
\end{solution}

\section{Sequential Compactness, Extreme Values, and Uniform Continuity}

\begin{theorem}[11.16]
  Every sequentially compact subset of \(\mb R^n\) is bounded and closed.
\end{theorem}

\begin{proof}
    Let \(A\) be a sequentially compact subset of \(\mb R^n\). Suppose
    on the contrary that \(A\) is not bounded. Then, by definition
    (negating quantifiers), for every number \(M\) there exists a 
    point \(\vect u \in A\) such that \(\|\vect u\| > M \). In particular,
    there exists a \(\vect u_k\) for each natural number \(k\) where
    this holds. This forms a sequence \(\{\vect u_k\}\) in \(A\). 
    Because \(A\) is sequentially compact, a subsequence \(\{\vect u_{k_j}\}\)
    of \(\{\vect u_k\}\) converges to some \(\vect u\) in \(A\).
    A consequence of convergence is that \(\vect u_{k_j} \to \vect u\) implies 
    \(\|\vect u_{k_j}\| \to \|\vect u\|\), but we assumed that
    \(\|\vect u_{k_j}\| > k_j \geq j\) (recall that \(k_j\) is increasing).
    This is a contradiction. Thus, \(A\) is bounded.

    Now, suppose we have a sequence \(\{\vect v_k\}\) in \(A\) that converges
    to \(\vect v\). We must show that \(\vect v \in A\). Because \(A\)
    is sequentially compact, a subsequence \(\{\vect v_{k_j}\}\) converges
    to a point in \(A\). Since \(\vect v_k \to \vect v\), we must have
    \(\vect v_{k_j} \to \vect v\), and so \(\vect v \in A\). Thus, \(A\)
    is closed.
\end{proof}

\begin{theorem}[11.17]
  Every bounded sequence in \(\mb R^n\) has a convergent subsequence.
\end{theorem}

\begin{proof}
    This is a proof by induction on the dimension of the vector space.
    If \(n = 1\), then this follows from Theorem 2.33. Suppose this
    property holds for \(n > 1\) and now consider the \(n + 1\) case.
    Let \(\{\vect u_k\}\) be a bounded sequence in \(\mb R^{n+1}\).
    For each \(k\), we can write
    \[ \vect u_k = (u_1, u_2, ...., u_n, u_{n+1}) = (\vect v_k, x_k) \]
    where \(\vect v_k = (u_1, u_2, ..., u_n)\) and \(x_k = u_{n+1}\).  
    Now, \(\vect v_k\) is a sequence in \(\mb R^n\) and so 
    has a convergent subsequence \(\vect v_{k_j} \to \vect v\). 
    Using the same indices, we have \(x_{k_j}\). This is a sequence in \(\mb R\)
    and so we have a convergent subsequence \(x_{k_{j_h}} \to x\). 
    It follows that \((\vect v_{k_{j_h}}, x_{k_{j_h}}) \to (\vect v, x)\)
    by the componentwise convergence criterion. Letting \(\vect u = (v_1, v_2, ..., v_n, x)\),
    this means that \(\{\vect u_k\}\) has a subsequence that converges
    to \(\vect u\), as desired.
\end{proof}

\begin{theorem}[11.18, The Sequential Compactness Theorem]
  A subset of \(\mb R^n\) is sequentially compact if and only if
  it is closed and bounded.
\end{theorem}

\begin{proof}
    Theorem 11.16 proved one direction. Hence, we must show that 
    a closed and bounded set \(A\) is sequentially compact. Let
    \(\{\vect u_k\}\) be a sequence in \(A\). By the previous Theorem,
    \(\{\vect u_k\}\) has a convergent subsequence: \(\vect u_{k_j} \to \vect u\).
    But since \(A\) is closed, \(\vect u \in A\). Hence, \(A\)
    is sequentially compact.
\end{proof}

\begin{corollary}[11.19]
  The generalized rectangle
  \(\prod_{i=1}^n[a_i,b_i]=[a_1,b_1]\times\dots\times[a_n,b_n]\subseteq\mb R^n\)
  is sequentially compact.
\end{corollary}

\begin{proof}
    Let \(C_1, C_2, ... , C_n\) be closed sets, and let \(\vect u_k\) be 
    a sequence in \(\prod_{i=1}^n C_i \) that converges to \(\vect u\). 
    By the componentwise convergence criterion, we have 
    \(p_i(\vect u_k) \to p_i(\vect u)\). Now since \(\{p_i(\vect u_k)\}\)
    is a convergent sequence in \(C_i\), and \(C_i\) is closed, 
    \(p_i(\vect u) \in C_i\) for \(i \in [n]\). Hence, \(\vect u \in \prod_{i=1}^n C_i\)
    and so \(\prod_{i = 1}^n C_i\) is closed.

    From an earlier result, we know that \([a_i, b_i]\) is closed. Hence
    we have that \(\prod_{i = 1}^n [a_i, b_i]\) is closed. 

    Next, let \(a = \text{min}\{a_1, a_2, ..., a_n\}\) and 
    \(b = \text{max}\{b_1, b_2, ..., b_n\}\). Then, the resulting interval
    \([a, b]\) is bounded by a number \(M\). Furthermore, 
    \([a_i, b_i] \subset [a,b]\) and so \([a_i, b_i]\) is bounded by \(M\)
    as well (for \(i \in [n]\)). Then, for \(\vect u \in \prod_{i=1}^n [a_i, b_i]\),
    we have \(|u_i| \leq M\) and so
    \[ \|\vect u\| = \sqrt{ \sumi u_i^2 } \leq \sqrt{n} M . \]
    This shows that \(\prod_{i=1}^n [a_i, b_i]\) is bounded. Therefore, the
    generalized rectangle is sequentially compact.
\end{proof}

\begin{theorem}[11.20]
  Let \(A\subseteq\mb R^n\) and suppose \(F:A\to\mb R^m\) is continuous.
  If \(A\) is sequentially compact then \(F(A)\) is also sequentially
  compact.
\end{theorem}

\begin{proof}
    Let \(\vect v_k\) be a sequence in \(F(A)\). By definition of 
    the image, for each \(k\), there exists \(\vect u_k\) in \(A\)
    such that \(F(\vect u_k) = \vect v_k\). Since \(A\) is sequentially
    compact, we have a subsequence \(\{\vect u_{k_j}\}\) that converges
    to a point \(\vect u\) in \(A\). Then by continuity, we have
    that \(\vect u_{k_j} \to \vect u\) implies 
    \(F(\vect u_{k_j}) = v_{k_j} \to F(\vect u)\). Thus, \(F(A)\) is 
    sequentially compact.
\end{proof}

\begin{lemma}[11.21]
  Every nonempty seqeuntially compact subset of \(\mb R\) has a
  maximum and minimum element.
\end{lemma}

\begin{proof}
    Let \(A\) be a nonempty sequentially compact subset of \(\mb R\).
    Then \(A\) is bounded. By the Completeness axiom, \(A\) has a
    supremum \(b\). We show that \(b \in A\). For every natural number
    \(k\), \(b - \frac{1}{k}\) is not an upper bound of \(A\) and so
    there exists an element \(x_k \in (b - \frac{1}{k}, b]\). Since
    the sequence \(b - \frac{1}{k} \to b\), we have \(x_k \to b\).
    Since \(A\) is sequentially compact, \(A\) is closed and hence
    \(b \in A\). Repeat this argument for the infimum of \(A\) to 
    obtain the result.
\end{proof}

\begin{theorem}[11.22, The Extreme Value Theorem, Bolzano-Weierstrass Theorem]
  Let \(A\subseteq\mb R^n\) be nonempty sequentially compact
  and suppose \(f:A\to\mb R^m\) is continuous.
  Then \(f\) attains a smallest and largest value.
\end{theorem}

\begin{proof}
    Let \(F_i = p_i \circ f: A \rightarrow \mb R\) for \(i \in [m]\). 
    Since \(F_i\) is continuous and \(A\) is sequentially compact,
    so is \(F_i(A)\), which, by the lemma, means that the set has
    a largest and smallest element \(B_i\) and \(b_i\), respectively.
    It follows that \(B = (B_1, B_2, ..., B_m)\) and \(b = (b_1, b_2, ..., b_m)\)
    are the largest and smallest values of \(f(A)\) (using the
    norm for our ordering). 
\end{proof}

\begin{theorem}[11.24]
  Let \(A\subseteq\mb R^n\) be nonempty.
  \(A\) is sequentially compact if and only if
  every continuous \(f:A\to\mb R\) attains a smallest and largest value
  (i.e. it has the Extreme Value Property).
\end{theorem}

\begin{proof}
    Suppose \(A\) has the Extreme value property. Since the mapping
    \(g(\vect u) = \|\vect u\|\) is continuous on \(A\), \(g\)
    obtains a largest and smallest value. This implies that \(A\)
    is bounded. Let \(\{\vect v_k\}\) be a sequence in \(A\)
    that converges to \(\vect v\). Define \(h(\vect u) = \|\vect u - \vect v\|\)
    for all \(\vect u \in A\). Let \(\vect u_{\star}\) be the
    minimizer of \(h\) (since \(h\) is continuous). Now since
    \(dist(\vect v_k, \vect v) \to 0\) and \(h(\vect u) \geq 0\)
    for all \(\vect u \in A\), it follows that \(h(\vect u_{\star}) = 0\).
    In other words, \(\|\vect u_{\star} - \vect v\| = 0\), which 
    occurs only if \(\vect u_{\star} = \vect v\). Hence we have
    \(\vect v \in A\), which shows that \(A\) is closed. Therefore,
    \(A\) is sequentially compact.

    The other direction follows from Theorem 11.22.
\end{proof}

\begin{theorem}[11.25, Exercise 5]
  Let \(A\subseteq\mb R^n\) and \(f:A\to\mb R^m\) be continuous.
  If \(A\) is sequentially compact then \(f\) is uniformly continuous.
\end{theorem}

\begin{proof}
    Let \(\{\vect u_k\}\) and \(\{\vect v_k\}\) be sequences in \(A\)
    where \(\lim_{k \to \infty} dist(\vect u_k, \vect v_k) = 0\), but
    \[ \lim_{k \to \infty} dist(f(\vect u_k), f(\vect v_k)) \neq 0 .\] 
    Then by definition (negating quantifiers), there exists an 
    \(\epsilon_0 > 0\) such that for all \(N\), \(k \geq N\) implies
    \[ dist(f(\vect u_k), f(\vect v_k)) \geq \epsilon .\]
    Since \(A\) is sequentially compact, there exists subsequences
    \(\{\vect u_{k_j}\}\) and \(\{\vect v_{k_j}\}\) that converge
    in \(A\). Now since \(\lim_{k \to \infty} dist(\vect u_{k_j}, \vect v_{k_j}) = 0\),
    we have that the subsequences converge to the same point; 
    call this point \(\vect x_0\). By continuity, \(\vect u_{k_j} \to \vect x_0\)
    implies \(f(\vect u_{k_j}) \to f(\vect x_0)\). Likewise,
    \(\vect v_{k_j} \to \vect x_0\) implies \(f(\vect v_{k_j}) \to f(\vect x_0)\).

    By definition of a converging sequence, for \(\epsilon_0 / 2\)
    there exists \(N_u\) such that \(k_j \geq N_u\) implies
    \(dist(f(\vect u_{k_j}),  f(\vect x_0)) < \epsilon_0 / 2\).
    Likewise, there exists \(N_v\) such that \(k_j \geq N_v\) implies
    \(dist(f(\vect v_{k_j}), f(\vect x_0)) < \epsilon_0 / 2\). 
    Let \(N = \text{max}\{N_u, N_v\}\). By the Triangle inequality, for \(k_j \leq N\),
    \[ dist(f(\vect u_{k_j}), f(\vect v_{k_j})) \leq
    dist(f(\vect u_{k_j}), f(\vect x_0)) + dist(f(\vect x_0), f(\vect v_{k_j})) < 
    \frac{\epsilon_0}{2} + \frac{\epsilon_0}{2} = \epsilon_0 .\]
    This contradicts our earlier assumption, and so \(f\) is uniformly
    continuous.
\end{proof}

\begin{theorem}[11.27, Exercise 11]
  Let \(A\subseteq\mb R^n\) and \(f:A\to\mb R^m\).
  \(f\) is uniformly continuous if and only if for all \(\epsilon>0\)
  there exists \(\delta>0\) such that \(\|\vect u-\vect v\|<\delta\)
  implies \(\|f(\vect u)-f(\vect v)\|<\epsilon\).
\end{theorem}

\begin{proof}
    Suppose \(f\) is uniformly continuous, but the epsilon-delta
    criterion does not hold. Then there exists an \(\epsilon_0 > 0\)
    where for all \(\delta > 0\), \(\|\vect u - \vect v\| < \delta\)
    does not imply \(\|f(\vect u) - f(\vect v)\| < \epsilon \). So
    at an abritrary point \(\vect x \in A\), for each \(k\), there is a point \(\vect x_k\)
    where \(\|\vect x_k - \vect x\| < 1/k\) but 
    \(\|f(\vect x_k) - f(\vect x)\| \geq \epsilon \). This means
    \(\vect x_k \to \vect x\). So set \(\vect u_k = \vect x_n\) and
    \(\vect v_k = \vect x\) (constant sequence). By uniform continuity,
    \(\lim_{k \to \infty} \|\vect u_k - \vect v_k \| = 0\) implies
    \(\lim_{k \to \infty} \|f(\vect u_k) - f(\vect v_k)\| = 0\), a
    contradiction.

    Now suppose the converse. Let \(\{\vect u_k\}\) and \(\{\vect v_k\}\)
    be sequences in \(A\) where \(\lim_{k \to \infty} dist(\vect u_k, \vect v_k) = 0\).
    Let \(\epsilon > 0\). Then there exists \(\delta > 0\) such that
    \(\|\vect u - \vect v\| < \delta \) implies
    \(\|f(\vect u) - f(\vect v)\| < \epsilon \). In particular, we 
    have that for this \(\delta > 0\) an index \(N\) such that 
    \(k \geq N\) implies \( \|\vect u_k - \vect v_k\| < \delta\). Since
    this occurs, we have for \(k \geq N\),
    \( \|f(\vect u_k) - f(\vect v_k)\| < \epsilon \). This is precisely
    the definition of a convergent sequence. Hence,
    \( \lim_{k \to \infty} dist(f(\vect u_k), f(\vect v_k)) = 0\)
    and so \(f\) is uniformly continuous.
\end{proof}

\begin{exercise}[3,4]
  Recall that \(B_r(\vect u)=\{\vect v:\|\vect u-\vect v\|<r\}\).
  Is \(B_r(\vect u)\) bounded? Sequentially compact?
\end{exercise}

\begin{solution}
    The open ball is open and not closed, so it cannot
    be sequentially compact. However, it is bounded: for 
    \(\vect v \in B_r(\vect u)\), we have
    \[ \|\vect v\| \leq \|\vect u - \vect v\| + \|\vect u\| < r + \|\vect u\| .\]
    Since \(r\) and \(\vect u\) are fixed, the number
    \(M = r + \|\vect u\|\) is also fixed.  
\end{solution}

\begin{exercise}[2]
  Let \(D_r(\vect u)=\{\vect v:\|\vect u-\vect v\|\leq r\}\).
  Prove \(D_r(\vect u)\) is sequentially compact.
\end{exercise}

\begin{solution}
    The complement of \(D_r(\vect u)\) is open, and so
    \(D_r(\vect u)\) is closed. Then we know from the previous
    exercise that this set is also bounded. Hence, the
    set is sequentially compact.
\end{solution}

\begin{exercise}[optional, Heine-Borel Theorem]
  Let \(A\subseteq\mb R^n\). We say \(A\) is compact when for every
  collection \(\mathcal U\) such that \(U\) is open
  for all \(U\in\mathcal U\) and \(A\subseteq\bigcup\mathcal U\), there exists
  a finite subset \(\mathcal F\subseteq\mathcal U\) such that
  \(A\subseteq\bigcup\mathcal F\). Prove that \(A\) is compact if and only if
  \(A\) is closed and bounded.
\end{exercise}

\begin{solution}

    (\(\Rightarrow)\)
    Suppose \(A\) is compact, but that \(A\) is not bounded. Then
    for every natural number \(k\) there exists a point \(\vect x_k \in A\)
    such that \(\|\vect x_k\| > k \). Form the open collection
    \[ \mathcal U = \bigcup_{k \in \mb N} B_{k}(\vect 0) .\]
    Since \(\mathcal U\) covers \(\mb R^n\), it clearly covers \(A\). 
    By compactness, there is finite subcover 
    \(\bigcup_{i = 1}^{m} B_{k_i}(\vect 0) \) of \(A\). 
    Set \(K = \text{max}\{k_1, ..., k_m\}\). Then \(A \subseteq B_{K}(\vect 0)\),
    but this contradicts our assumption. Hence \(A\) is bounded.

    To prove that \(A\) is closed, we make the following observation:
    any two distinct points in \(\mb R^n\) have disjoint open neighborhoods.
    Let \(\vect x, \vect y\) be distinct. Then \(\|\vect x - \vect y\| > 0\)
    and so set \(\epsilon = \|\vect x - \vect y\| / 2\). It follows that
    \(B_{\epsilon}(\vect x)\) and \(B_{\epsilon}(\vect v)\) are disjoint.
    We call this the Hausdorff condition.

    We now show that \(A^c\) is open. Let \(\vect z \in A^c\). For 
    each point \(\vect v\) in \(A\), choose disjoint open neighborhoods
    \(Z_v\) and \(U_v\) for \(\vect z\) and \(\vect v\), respectively. 
    It follows that the collection \(\mathcal U = \bigcup_{\vect v \in A} U_v \) 
    is an open cover of \(A\). By compactness, we a finite subcover
    \[ \mathcal U_m = \bigcup_{i = 1}^m U_{v_i} .\]
    Since there are finitely many indices here, the set
    \[ Z = Z_{v_1} \cap ... \cap Z_{v_n} \]
    is open. Further, we have that \(\mathcal U_m\) and \(Z\)
    are disjoint, and because \(A \subset \mathcal U_m\),
    it follows that \(Z \subset A^c\) and contains \(\vect z\).
    Hence \(\vect z\) is an interior point of \(A^c\), and so
    \(A^c\) is open. Therefore \(A\) is closed.

    (\(\Leftarrow\))
    Next, suppose \(A\) is closed and bounded. This means that
    \(A\) is sequentially compact. I claim that given \(\epsilon > 0\),
    there exists a finite covering of \(A\) by open balls with
    radius \(\epsilon\). Suppose this wasn't true. Pick a point
    \(\vect u_1 \in A\). By assumption, \(B_{\epsilon}(\vect u_1)\)
    doesn't cover \(A\), and so pick \(\vect u_2 \in A / B_{\epsilon}(\vect u_1)\).
    Continue this procedure. In general, we have that point \(\vect u_{n + 1}\)
    is in \(A\) but not in \(B_{\epsilon}(\vect u_1) \cup ... \cup B_{\epsilon}(\vect u_n)\).
    This implies that \(dist(\vect u_{n+1}, \vect u_i) > \epsilon \) for 
    all \(i \in [n]\). However, \(\{\vect u_k\}\) is a sequence in \(A\),
    and since \(A\) is sequentially compact, \(\{\vect u_k\}\) must have
    a convergent subsequence. However, no two points have distance less
    than \(\epsilon\), a contradiction.

    So far so good. Next I claim that for any open covering \(\mathcal U\) of
    \(A\), there is a \(\delta > 0\) such that each subset \(X \subset A\)
    having a diameter less than \(\delta\) is contained in an element 
    of \(\mathcal U\): \(X \subset U\). Note: by diameter,
    I mean \(\text{diam}(X) = \text{sup}\{dist(\vect x, \vect y)\}\) 
    for \(\vect x, \vect y \in X\). Since \(A\) is bounded, this number will
    exist.
    
    We proceed by contradiction. For each natural number \(k\), there exists
    a subset \(X_{k}\) having diameter less than \(1/k\) not contained in 
    any \(U \in \mathcal U\). Pick a point \(\vect u_k \in X_k\). Since \(A\)
    is sequentially compact, there is a convergent subsequence 
    \(\vect u_{k_j} \to \vect u\). Since \(\vect u \in A\), \(\vect u \in U\)
    for some \(U \in \mathcal U\) (definition of open cover). Because \(U\) is open, 
    there exists \(\epsilon > 0\) such that \(B_{\epsilon}(\vect u) \subset U\). 
    Pick \(j\) large enough so that \(1 / k_j < \epsilon / 2\) and 
    \(dist(\vect u_{k_j}, \vect u) < \epsilon/2 \). It follows that
    \(X_{k_{j}} \subset B_{\epsilon/2}(\vect u_{k_j})\) (because its diameter
    is smaller than the radius of the open ball), and that for any \(\vect v \in X_{k_j}\),
    \[ dist(\vect v, \vect u) \leq dist(\vect v, \vect u_{k_j}) + dist(\vect u_{k_j}, \vect u)
    < \epsilon /2 + \epsilon / 2 = \epsilon .\]
    Thus, \(X_{k_{j}} \subset B_{\epsilon}(\vect u) \subset U\), a contradiction.

    Putting the previous two facts together, we can now prove the theorem. Let
    \(\mathcal U\) be an open cover of \(A\). Pick \(\epsilon = \delta / 3\), where
    \(\delta\) is the number corresponding to this particular open cover. We 
    find a finite covering of \(A\) by these open balls of radius \(\epsilon\). Since
    each open ball will have a diameter less than \(\epsilon\), they will lie
    in some element of \(\mathcal U\). For each ball, keep the element of \(\mathcal U\)
    containing it. This is a finite subcover of \(\mathcal U\). Thus, \(A\) is compact.


\end{solution}




\chapter{Metric Spaces}

\begin{definition}
  A pair \((X,d)\) is called a \textit{metric space} if \(X\) is a set
  and \(d\) is a function \(d:X^2\to[0,\infty)\) satisfying the following
  properties:
  \begin{itemize}
    \item Identity: \(d(p,q)=0\) if and only if \(p=q\).
    \item Symmetry: \(d(p,q)=d(q,p)\).
    \item Triangle Inequality: \(d(p,q)\leq d(p,w)+d(w,q)\).
  \end{itemize}
\end{definition}

\begin{theorem}[12.2]
  \(dist(\vect p,\vect q)=\|\vect q-\vect p\|\) is
  a metric on \(\mathbb R^n\).
\end{theorem}

\begin{proof}
    First, \(\vect q = \vect p\) iff \(\vect q - \vect p = \vect 0\) 
    iff \(\|\vect q - \vect p\| = 0\) since, in the definition,
    \((q_i - p_i)^2 \geq 0\) for \(i \in [n]\). Next, since 
    \((q_i - p_i)^2 = (p_i - q_i)^2\), we have 
    \(\|\vect q - \vect p\| = \|\vect p - \vect q\|\). Last,
    \begin{align*}
        d(p, q) &= \|\vect q - \vect p\| \\
        &= \|(\vect q - \vect w) + (\vect w - \vect p)\| \\
        &\leq \|\vect q - \vect w\| + \|\vect w - \vect p\| \\
        &= \|\vect w - \vect p\| + \|\vect q - \vect w\| \\
        &= d(p, w) + d(w, q) \\
    \end{align*}
\end{proof}

\begin{definition}
  Let \((X,d)\) be a metric space. For \(p\in X,r>0\),
    \[ B_r(p)=\{q\in X:d(p,q)<r\} \]
  is the open ball about \(p\) with radius \(r\). For \(A\subseteq X\),
  \begin{itemize}
    \item \(\interior A = \{q\in A:\exists r>0(B_r(q)\subseteq A)\}\)
    \item \(\exterior A = \{q\in A:\exists r>0(B_r(q)\subseteq X\setminus A)\}\)
    \item \(\boundary A = \{q\in A:\forall r>0(B_r(q)\cap A\not=\emptyset\text{ and }B_r(q)\setminus A\not=\emptyset)\}\)
  \end{itemize}
  Call \(A\) open in \((X,d)\) if \(A=\interior A\).
  Note that these concepts match the definitions we gave for \(\mb R^n\)
  using the metric \(d(\vect p,\vect q)=\|\vect q-\vect p\|\).
\end{definition}

\begin{theorem}[12.8]
  Let \((X,d)\) be a metric space. Let \(p\in X,r>0\). Then
  \(B_r(p)\) is open.
\end{theorem}

\begin{proof}
    By definition of the interior, \(\interior B_r(p) \subset B_r(p)\). Let
    \(q \in B_r(p)\). Let \(R = r - d(p, q)\). Then for \(u \in B_R(q)\), we
    have 
    \[ d(u, p) \leq d(u, q) + d(q, p) < r - d(q, p) + d(p, q) = r \]
    so that \(u \in B_r(p)\). Because \(u\) was arbitrary, this implies
    \(B_R(q) \subset B_r(p)\) and so \(B_r(p) \subset \interior B_r(p)\).
    Therefore, \(B_r(p) = \interior B_r(p)\) and so \(B_r(p)\) is open. 
\end{proof}

\begin{definition}
  Let \(d\) be a metric on \(\mb R^n\). We say \(d\) is \textit{compatible
  with the usual topology on \(\mb R^n\)} if the open sets determined by
  \(d\) are exactly the open sets determined by \(dist\).
\end{definition}


\begin{example}
  \(s:\mb R^n\to[0,\infty)\) defined by
  \(s(\vect u,\vect v)=\max\{|p_i(\vect v)-p_i(\vect u)|:1\leq i\leq n\}\)
  is a metric on \(\mb R^n\).
\end{example}

\begin{proof}
    First, it's clear that \(\vect u = \vect v\) iff \(\vect v - \vect u = \vect 0\). Then
    \[ \vect u = \vect v \Leftrightarrow \max\{ |p_i(\vect v) - p_i(\vect u)|\} = 
    \max\{ |p_i(\vect v - \vect u)|\} = \max\{ |p_i(\vect 0)|\} = 0 .\]
    
    Second, because of the absolute value, 
    \[ s(\vect u, \vect v) = \max\{ |p_i(\vect v) - p_i(\vect u)| \} = 
    \max \{ |p_i(\vect u) - p_i(\vect v)|\} = s(\vect v, \vect u) .\]

    % TODO: Finish this example!
\end{proof}

\begin{theorem}
  \(s\) is compatible with the usual topology on \(\mb R^n\).
\end{theorem}
\begin{proof}

\end{proof}


\begin{example}
  \(t:\mb R^n\to[0,\infty)\) defined by
  \(t(\vect u,\vect v)=\sum_{i=1}^n |p_i(\vect v)-p_i(\vect u)|\)
  is a metric on \(\mb R^n\).
\end{example}
\begin{proof}

\end{proof}

\begin{theorem}
  \(t\) is compatible with the usual topology on \(\mb R^n\).
\end{theorem}
\begin{proof}

\end{proof}

\begin{definition}
  \(d:X\to[0,\infty)\) defined by
  \(d(p,q)=1\) for \(p\not=q\)
  and \(d(p,p)=0\)
  is called a \textit{discrete metric} on \(X\).
\end{definition}


\begin{theorem}[12.4]
  The discrete metric on \(X\) is a metric.
\end{theorem}
\begin{proof}

\end{proof}

\begin{theorem}
  The discrete metric on \(\mb R^n\) is not compatible with the usual
  topology on \(\mb R^n\). (Hint: show that every subset of a discrete
  metric space is open.)
\end{theorem}
\begin{proof}

\end{proof}

\begin{definition}
  Let \(C([a,b],\mb R)\) be the set of all continuous functions
  \(f:[a,b]\to\mb R\), and for \(f,g\in C([a,b],\mb R)\) let
  \(d(f,g)=\max\{|f(x)-g(x)|:x\in[a,b]\}\).
\end{definition}

\begin{theorem}[12.3]
  \(d(f,g)=\max\{|f(x)-g(x)|:x\in[a,b]\}\) is a metric on \(C([a,b],\mb R)\).
\end{theorem}

\begin{proof}
    It's clear that if \(f\) and \(g\) are continuous, so is
    \(f - g\) and consequently, \(|f - g|\). Then since the domain is a compact
    set, the Extreme value theorem applies and so \(d(f, g)\) is well-defined.

    First, \(d(f, g) = 0\) iff \(\max\{|f - g|(x) : x \in [a,b]\} = 0\), which
    due to the absolute value, happens iff \(|(f - g)(x)| = 0\) for all \(x \in [a,b]\).
    This means that \(f - g\) is the zero function, and consequently,
    \(f(x) = g(x)\) on \([a,b]\). In other words, \(d(f, g) = 0 \Leftrightarrow f = g\).
    Again, the absolute value implies that \(d(f,g) = d(g, f)\).

    Last,
    \begin{align*} 
        d(f, h) &= \max\{ |f(x) - h(x)| : x \in [a,b] \} \\
                &= \max\{ |f(x) - g(x) + g(x) - h(x)| : x \in [a,b] \} \\
                &\leq \max\{ |f(x) - g(x)| + |g(x) - h(x)| : x \in [a,b] \} \\
                &\leq \max\{ |f(x) - g(x)| : x \in [a, b] \} + \max\{ |g(x) - h(x)| : x \in [a,b] \} \\
                &= d(f, g) + d(g, h) \\
    \end{align*}

    The third step applies the Triangle inequality to the absolute value. The
    fourth step means that \(|f - g|\) can achieve its maximum at a different value
    of \(x\) than \(|g - h|\), and so this sum may be larger than the maximum of 
    \(\max\{ [|f - g| + |g - h|](x) : x \in [a,b] \} \), taken pointwise.

\end{proof} 

\begin{definition}
  Let \(\{p_k\}\) denote a \textit{sequence} in a metric space \((X,d)\),
  i.e. a function from \(\mb N\) to \(X\).
\end{definition}

\begin{definition}
  We say the sequence \(\{p_k\}\) \textit{converges} to \(p\in X\)
  when \[\lim_{k\to\infty}d(p_k,p)=0.\]
\end{definition}

\begin{definition}
  \(C\subseteq X\) is said to be \textit{closed} in the metric space
  \((X,d)\) when for every sequence \(\{p_k\}\) of points in \(C\)
  converging to \(p\in X\), it follows that \(p\in C\).
\end{definition}

\begin{example}[12.11]
  The set \(\{f\in C([a,b],\mb R):f(x)\geq 0\}\) is closed.
\end{example}

\begin{proof}
    Let \(\{f_k\}\) be a sequence of functions in the above set
    that converge to \(f\). We show that \(f(x) \geq 0\) on \([a,b]\).

    % TODO: FINISH THIS PROOF 
\end{proof}

\begin{theorem}[12.12, The Complementing Characterization]
  Let \((X,d)\) be a metric space and \(A\subseteq X\). Then \(A\) is
  open in \((X,d)\) if and only if \(X\setminus A\) is closed in \((X,d)\).
\end{theorem}

\begin{proof}
    Suppose \(A\) is open. Let \(\{p_k\}\) be a sequence in \(X \setminus A\)
    that converges to \(p\), but suppose \(p \not\in X \setminus A\).
    Then \(p \in A\), and since \(A\) is open, there exists \(\epsilon > 0\)
    such that \(B_{\epsilon}(p) \subset A\). By definition of
    convergence, for this \(\epsilon\), there exists \(N\) such that \(k \geq N\) implies
    \(d(p_k, p) < \epsilon\). However, this means \(p_k \in A\) since
    \(p_k \in B_{\epsilon}(p)\), but cannot happen since we assumed
    \(p_k \in X \setminus A\). Thus, \(p \in X \setminus A\) and so this
    set is closed.

    Conversely, suppose \(X \setminus A\) is closed. Let \(p \in A\). 
    Suppose on the contrary there exists no \(r > 0\) such that
    \(B_r(p) \subset A\). Then for every natural number \(k\), 
    \(B_{1/k}(p) \cap X \setminus A\) is nonempty. Pick a point from
    this intersection and call it \(p_k\). It follows that \(\{p_k\}\)
    is a sequence of points in \(X \setminus A\) that converge to 
    \(p\). But, since \(X \setminus A\) is closed, \(p\) should be in 
    \(X \setminus A\), a contradiction. Hence, there exists a \(r > 0\) such that
    \(B_r(p) \subset A\). Therefore, \(A\) is open.
\end{proof}

\begin{definition}
  A sequence \(\{p_k\}\) in a metric space \((X,d)\) is called a
  \textit{Cauchy sequence} when for each \(\epsilon>0\) there is an
  \(N\in\mb N\) such that \(k,l\geq N\) implies \(d(p_k,p_l)<\epsilon\).
\end{definition}

\begin{proposition}[12.15]
  Every convergent sequence in a metric space is Cauchy.
\end{proposition}

\begin{proof}
    Suppose \(p_k \to p\) in metric space \((X, d)\). Let \(\epsilon > 0\).
    Then by definition of convergence, for \(\epsilon / 2\), there
    exists integers \(N_0, N_1\) such that \(k \geq N_0\), \(l \geq N_1\)
    implies \( d(p_k, p ) < \epsilon/2\) and \(d(p_l, p) < \epsilon / 2\),
    respectively. Now pick \(N = \max\{N_0, N_1\}\). Then, for \(k, l \geq N\),
    we have
    \[ d(p_k, p_l) \leq d(p_k, p) + d(p, p_l) < \epsilon/2 + \epsilon/2 = \epsilon .\]
    Thus, \(\{p_k\}\) is a Cauchy sequence.
\end{proof}

\begin{lemma}[9.3]
  Every Cauchy sequence in \((\mb R,dist)\) is bounded.
\end{lemma}

\begin{proof}
    Let \(\epsilon > 0\) and \(\{p_k\}\) be a Cauchy sequence.
    By definition, there exists integer \(N\) such that \(k, l \geq N\) implies 
    \(d(p_k, p_l) < \epsilon\). Set 
    \(M = \max\{ |p_1|, |p_2|, ..., |p_{N-1}|, |p_N| + \epsilon \} \).
    Then for an arbitary index \(j\): if \(j < N\), \(|p_j| \leq M\) trivially;
    otherwise,
    \[ |p_j| = |(p_j - p_N) + p_N| \leq |p_j - p_N| + |p_N| < \epsilon + |p_N| \leq M .\]
\end{proof}

\begin{theorem}[9.4]
  A sequence in \((\mb R,dist)\) is Cauchy if and only if it is convergent.
\end{theorem}

\begin{proof}
    Since \((\mb R, dist)\) is a metric space, every convergent sequence is Cauchy.
    Now suppose \(\{p_k\}\) is Cauchy. By the previous lemma, \(\{p_k\}\) is bounded.
    Consequently, this sequence has a convergent subsequence \(p_{k_j} \to p\) (following
    from the fact that every sequence has a monotone subsequence, and since it is bounded,
    must converge). By definition of a Cauchy sequence, for \(\epsilon/2 > 0\), there
    exists integer \(N_0\) such that \(k, k_j \geq N_0\) implies \(d(p_k, p_{k_j}) < \epsilon/2\).
    By definition of convergence, for \(\epsilon/2\), there exists integer \(N_1\)
    such that \(k_j \geq N_1\) implies \(d(p_{k_j}, p) < \epsilon/2\). Combining
    the two, with \(N = \max\{N_0, N_1\}\), \(k \geq N\) implies
    \[ d(p_k, p) \leq d(p_k, p_{k_j}) + d(p_{k_j}, p) = \epsilon/2 + \epsilon/2 = \epsilon .\]
    Hence, every Cauchy sequence converges.
\end{proof}

\begin{corollary}[Example 12.16]
  A sequence in \((\mb R^n,dist)\) is Cauchy if and only if it is convergent.
\end{corollary}

\begin{proof}
    By the Componentwise convergence criterion, a sequence \(\{\vect u_k\}\) converges
    iff each of its coordinate sequences converges \(\{p_i(\vect u_k)\}\). Since the latter
    are in \((\mb R, dist)\), these sequences converge iff they are Cauchy. Using 
    \(\epsilon / \sqrt{n} > 0\), \(k, j \geq N_i\) implies 
    \[ |p_i(\vect u_k) - p_i(\vect u_j)| < \epsilon/ \sqrt{n} . \]
    Taking \(N = \max\{N_1, N_2, ..., N_n\}\), we get \(k, j \geq N\) implies
    \[ dist(\vect u_j, \vect u_k) = \sqrt{\sumi [p_i(\vect u_j) - p_i(\vect u_k)]^2} 
    < \sqrt{ \sumi \epsilon^2/n } = \sqrt{\epsilon^2} = \epsilon \]
    
\end{proof}

\begin{definition}
  A \textit{complete metric space} is a metric space where every
  Cauchy sequence is convergent.
\end{definition}




\chapter{Differentiating Functions of Several Variables}


\section{Limits}

\begin{definition}
  Let \(A\subseteq\mb R^n\). We call \(\vect x_*\in\mb R^n\) a
  \textit{limit point} of \(A\) in the case that there exists a sequence
  in \(A\setminus\{\vect x_*\}\) which converges to \(\vect x_*\).
\end{definition}

\begin{definition}
  Let \(A\subseteq\mb R^n\) have a limit point \(x_*\in\mb R\), and
  \(f:A\to\mb R\) be a function. Then we say the
  \textit{limit of \(f\) as \(\vect x\) approaches \(\vect x_*\)}
  is \(L\in\mb R\), or
  \[
    \lim_{\vect x\to\vect x_*} f(\vect x)
      =
    L
  \]
  in the case that whenever \(\{\vect x_k\}\) is a sequence of points in
  \(A\setminus\{\vect x_*\}\) converging to \(\vect x_*\),
  then \(\{f(\vect x_k)\}\) is a sequence of real numbers which
  converges to \(L\).
\end{definition}

\begin{theorem}[13.3]
  Let\(A\subseteq\mb R^n\) and \(\vect x_*\) be a limit point of \(A\).
  Suppose the functions \(f,g:A\to\mb R\) satsify
  \[
    \lim_{\vect x\to\vect x_*} f(\vect x)
      =
    L_1
    ~~~\text{and}~~~
    \lim_{\vect x\to\vect x_*} g(\vect x)
      =
    L_2
  .\]
  Then
  \[
    \lim_{\vect x\to\vect x_*} [f(\vect x)+g(\vect x)]
      =
    L_1+L_2
  \]
  and
  \[
    \lim_{\vect x\to\vect x_*} [f(\vect x)g(\vect x)]
      =
    L_1L_2
  .\]
  And assuming \(g(\vect x)\not=0\) for \(x\in A\) and \(L_2\not=0\),
  \[
    \lim_{\vect x\to\vect x_*} [f(\vect x)/g(\vect x)]
      =
    L_1/L_2
  .\]
\end{theorem}
\begin{proof}

\end{proof}

\begin{example}[13.4]
  The limit
  \[
    \lim_{(x,y)\to(0,0)}\frac{xy}{x^2+y^2}
  \]
  does not exist.
\end{example}
\begin{proof}

\end{proof}

\begin{example}[13.5]
  \[
    \lim_{(x,y)\to(0,0)}\frac{x^3}{x^2+y^2}
      =
    0
  .\]
\end{example}
\begin{proof}

\end{proof}

\begin{exercise}[4]
  Let \(m,n\in\mb N\). Prove that
  \[
    \lim_{(x,y)\to(0,0)}\frac{x^ny^m}{x^2+y^2}
  \]
  exists if and only if \(m+n>2\).
\end{exercise}
\begin{solution}

\end{solution}

\begin{exercise}[5]
  Give an example of a subset \(A\subseteq\mb R\) and point \(x\in A\)
  such that \(x\) is not a limit point of \(A\).
\end{exercise}
\begin{solution}

\end{solution}

\begin{exercise}[12]
  Show that \(A\subseteq\mb R^n\) is closed if and only if it contains
  all its limit points.
\end{exercise}
\begin{solution}

\end{solution}


\section{Partial Derivatives}

\begin{definition}
  For each \(1\leq i\leq n\), let \(\vect e_i\in\mb R^n\)
  satisfy \(p_i(\vect e_i)=1\) and \(p_j(\vect e_i)=0\) for \(j\not=i\).
\end{definition}

\begin{definition}
  Let \(\vect x\in U\subseteq\mb R^n\) with \(U\) open. For a function
  \(f:U\to\mb R\), define its \textit{first-order
  partial derivative with respect to
  its \(i\)th component at \(\vect x\)} to be
  \[
    \left[\frac{\partial}{\partial x_i}f\right](\vect x)
      =
    \frac{\partial f}{\partial x_i}(\vect x)
      =
    f_{x_i}(\vect x)
      =
    \lim_{t\to 0}\frac{f(\vect x+t\vect e_i)-f(\vect x)}{t}
  \]
  whenever the limit exists.
\end{definition}

\begin{definition}
  Let \(U\subseteq\mb R^n\) be open. For a function
  \(f:U\to\mb R\) such that \(f_{x_i}(\vect x)\) exists for all \(\vect x\in U\),
  let \(f_{x_i}:U\to\mb R^n\) be defined as its
  \textit{first-order partial derivative with respect to
  its \(i\)th component}.
\end{definition}

\begin{definition}
  Let \(U\subseteq\mb R^n\) be open. A function
  \(f:U\to\mb R\) such that \(f_{x_i}\) exists for all \(1\leq i\leq n\) is said
  to have \textit{first-order partial derivatives}.
\end{definition}

\begin{example}[13.8*]
  If \(f:\mb R^3\to\mb R\) is defined by
  \[
    f(x,y,z)=xyz-3xy^2
  \]
  then \(f_y:\mb R^3\to\mb R\) satisfies
  \[
    f_y(x,y,z)=xz-6xy
  .\]
\end{example}
\begin{proof}

\end{proof}

\begin{example}[13.9]
  The function \(f:\mb R^2\to\mb R\) defined by
  \[
    f(x,y) = \begin{cases}
      xy/(x^2+y^2) & \text{if } (x,y)\not=(0,0) \\
      0 & \text{if } (x,y)=(0,0) \\
    \end{cases}
  \]
  has first-order partial derivatives, but is not continuous.
\end{example}
\begin{proof}

\end{proof}

\begin{definition}
  Let \(U\subseteq\mb R^n\) be open. Then a function
  \(f:U\to\mb R\) is \textit{continuously differentiable} provided that
  \(f_{x_i}:U\to\mb R\) exists and is continuous for \(1\leq i\leq n\).
\end{definition}

\begin{definition}
  Let \(U\subseteq\mb R^n\) be open, and \(f:U\to\mb R^n\) have first-order
  partial derivatives. Then for \(1\leq i,j\leq n\) let
  \[
    \frac{\partial^2 f}{\partial x_j\partial x_i}
      :
    U \to \mb R
  \]
  be the partial derivative of \(\partial f/\partial x_i:U\to\mb R\)
  with respect to its \(j\)th component. This is also denoted by
  \(f_{x_ix_j}\). When \(i=j\), this is also denoted by
  \(\frac{\partial^2 f}{\partial x_i^2}\).
\end{definition}

\begin{definition}
  Let \(U\subseteq\mb R^n\) be open. A function
  \(f:U\to\mb R\) such that \(f_{x_ix_j}\) exists for all
  \(1\leq i,j\leq n\) is said
  to have \textit{second-order partial derivatives}.
\end{definition}

\begin{definition}
  Let \(U\subseteq\mb R^n\) be open. A function
  \(f:U\to\mb R\) such that \(f_{x_ix_j}\) exists and is continuous for all
  \(1\leq i,j\leq n\) is said
  to have \textit{continuous second-order partial derivatives}.
\end{definition}

\begin{lemma}[13.11]
  Let \(U\subseteq \mb R^2\) be open and nonempty, and suppose
  \(f:U\to\mb R\) has second-order partial derivatives. Then there are
  points \((x_1,y_1),(x_2,y_2)\in U\) such that
  \(f_{xy}(x_1,y_1)=f_{yx}(x_2,y_2)\).
\end{lemma}
\begin{proof}

\end{proof}

\begin{theorem}[13.10]
  Let \(U\subseteq \mb R^n\) be open and nonempty, and suppose
  \(f:U\to\mb R\) has continuous second-order partial derivatives.
  Then for all \(1\leq i,j\leq n\), it follows that
  \(f_{x_ix_j}=f_{x_jx_i}\).
\end{theorem}
\begin{proof}[Proof for n=2]

\end{proof}

\begin{example}[13.12, exercise 13]
  The function \(f:\mb R^2\to\mb R\) defined by
  \[
    f(x,y) = \begin{cases}
      xy(x^2-y^2)/(x^2+y^2) & \text{if } (x,y)\not=(0,0) \\
      0 & \text{if } (x,y)=(0,0) \\
    \end{cases}
  \]
  has second-order partial derivatives, but
  \[
    f_{xy}(0,0)=-1
      ~~~\text{while}~~~
    f_{yx}(0,0)=1
  .\]
\end{example}
\begin{proof}

\end{proof}

\begin{exercise}[4]
  Prove that \(g:\mb R^2\to\mb R\) satisfying \(|g(x,y)|\leq x^2+y^2\)
  must have partial derivatives with respect to both \(x\) and \(y\)
  at the point \((0,0)\).
\end{exercise}
\begin{solution}

\end{solution}







\chapter*{Midterm Part 3}

Choose two of the below problems (which you did not choose for
Part 2) and typeset your solutions. Delete the other three.
Each will be worth 20/100 points towards your midterm grade
for a total of 40/100 points.


\begin{exercise}[1]
Prove that if \(Q_n\) is a partition of \([a,b]\) refining
the partition \(P_n\) of \([a,b]\) for each
natural number \(n\), and \(\{P_n\}\) is an Archimedian sequence of
partitions for \(f\) on \([a,b]\), then \(\{Q_n\}\) is also Archimedian.
\end{exercise}

\begin{solution}
    By definition of an Archimedean sequence, we have 
    \[\limit [U(f, P_n) - L(f, P_n) ] = 0 . \]
    Since \(Q_n\) refines \(P_n\), by the Refinement lemma
    \[ L(f, P_n) \leq L(f, Q_n) \text{~and~} U(f, Q_n) \leq U(f, P_n) \]
    so that 
    \[ 0 \leq U(f, Q_n) - L(f, Q_n) \leq U(f, P_n) - L(f, P_n) \]
    for each \(n \in \mb N\). Taking the limit as \(n\) approaches
    infinity, we get
    \[ 0 \leq \limit [U(f, Q_n) - L(f, Q_n)] \leq \limit [U(f, P_n) - L(f, P_n)] = 0 \]
    and hence, \(\limit [U(f, Q_n) - L(f, Q_n)] = 0\). Therefore,
    \(\{Q_n\}\) is also an Archimedean sequence.   
\end{solution}

\begin{exercise}[2]
Explain the error(s) in the following ``proof'',
and then give a counterexample showing that the theorem is false.

\textbf{Theorem:} If \(f:[0,1]\to\mathbb R\) is integrable, then
\(f\) is also continuous.

\textbf{Proof:}
Since \(f\) is integrable, we may define \(F:[0,1]\to\mathbb R\)
by \(F(x)=\int_0^x f\). It follows
that \(F(x)\) is a differentiable function, because it is an antiderivative
of \(f\). Thus \(\frac{d}{dx}[F(x)]=f(x)\) by the Second Fundamental
Theorem of Calculus. Since the derivative of any differentiable function
is continuous, we conclude \(f\) is continuous.
\end{exercise}
\begin{solution}

\end{solution}

\begin{exercise}[3]
Recall that an \textbf{even} function satisfies the condition \(f(x)=f(-x)\).
Let \(f:\mathbb R\to\mathbb R\) be an even continuous function.
Prove that
\[
  \frac{d}{dx}\left[\int_{-x}^x f\right]=2f(x)
.\]

(Hint: Corollary 6.30 says that \(\frac{d}{dx}[\int_{x}^0f]=-f(x)\).)
\end{exercise}

\begin{solution}
    By Theorem 6.12, we can express the above integral as
    \[ \int_{-x}^{x} f = \int_{-x}^{0} f + \int_{0}^{x} f .\]
    Then, by the sum rule for derivatives, we have
    \[ \frac{d}{dx} \left[\int_{-x}^{x} f \right] = 
    \frac{d}{dx} \left[\int_{-x}^{0} f  + \int_{0}^{x} f \right] =
    \frac{d}{dx} \left[ \int_{-x}^{0} f \right] + 
    \frac{d}{dx} \left[ \int_{0}^{x} f \right] .\]
    The Second Fundamental Theorem of Calculus tells us that 
    \[ \frac{d}{dx} \left[ \int_{0}^{x} f \right] = f(x) .\]
    Now, define \(g(x) = -x\) on \(\mb R\). Then 
    \(g((-x, x)) \subseteq (-x, x)\) and so by Corollary 6.30
    and 6.32, we have
    \[ \frac{d}{dx} \left[ \int_{-x}^{0} f \right] = 
       \frac{d}{dx} \left[ \int_{g(x)}^{0} f \right] =
       - f(g(x)) g'(x) = - f(-x) (-1) = f(-x) = f(x) ,\]
    the last step following from \(f\) being an even function. 
    Altogether,
    \[ \frac{d}{dx} \left[\int_{-x}^{x} f \right] = 
       \frac{d}{dx} \left[ \int_{-x}^{0} f \right] + 
       \frac{d}{dx} \left[ \int_{0}^{x} f \right]  = 
       f(x) + f(x) = 2f(x) .\]
\end{solution}

\begin{exercise}[4]
Prove the following theorem:

Let \(\vect x\in\mathbb R^n\) and let \(\{\vect x_k\}\) be a sequence
of points in \(\mathbb R^n\). If for every open set \(U\)
containing \(\vect x\), there is an index \(K\) such that
\(\vect x_k\in U\) for all \(k\geq K\),
then \(\{\vect x_k\}\) converges to \(\vect x\).

(Hint: \(B_\epsilon(\vect x)\) is open.)
\end{exercise}
\begin{solution}

\end{solution}

\begin{exercise}[5]
Prove that any finite subset of \(\mathbb R^n\) is closed.

(Hint: First
prove that any singleton subset of \(\mathbb R^n\) is closed.)
\end{exercise}
\begin{solution}

\end{solution}


\end{document}


